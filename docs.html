<!DOCTYPE html>
<html>
<head>
  <meta content="text/html;" http-equiv="Content-Type">
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <link rel="icon" href="ensmallen_icon.png" type="image/png">
  <link type="text/css" rel="stylesheet" href="style.css">
  <title>ensmallen: flexible C++ library for efficient mathematical optimization</title>
</head>
<body>

<div id="ens_header">
<div id="ens_header_row">
  <div id="ens_header_cell_logo_img"><a href="http://ensmallen.org"><img id="ens_logo_img" src="ensmallen_logo.png" alt="ensmallen" align="top" border="0"></a></div>
  <div id="ens_header_spacer"></div>
  <div id="ens_header_cell_logo_txt"><big><big><b>en</b>small<b>en</b></big><br>flexible C++ library for efficient mathematical optimization</big></div>
</div>
</div>



<div id="ens_menu">
  <ul class="ens_menu">
  <li class="ens_menu"><a class="ens_menu" href="index.html">Home</a></li>
  <li class="ens_menu"><a class="ens_menu_selected" href="docs.html">Documentation</a></li>
  <li class="ens_menu"><a class="ens_menu" href="developers.html">Developers</a></li>
  <li class="ens_menu"><a class="ens_menu" href="questions.html">Questions</a></li>
  </ul>
</div>

<div id="ens_content">


<!-- BEGIN CONTENT -->


<style type="text/css">
<!--
@media all
  {
  .pagebreak { }
  .noprint   { }
  }

@media print
  {
  .pagebreak { page-break-before: always; }
  .noprint   { display: none !important;  }
  }
-->
</style>

<a class="noprint" style="display:scroll; position:fixed; bottom:5px; right:5px;" href="#top"><font size=-1>[top]</font></a>

<a name="top"></a>
<big><b>API documentation for ensmallen 1.10</b></big>
<br>
<br>


<!-- uncomment the block below once we have a publication -->
<!--
<b>Citations</b>
<ul>
<li>
Please cite the following paper if you use ensmallen in your research and/or software.
<br>
Citations are useful for the continued development and maintenance of the library.
<br>
<br>
[under construction]
</li>
</ul>
-->

<p>ensmallen is used to find the minimum of a mathematical function.  To do
this, a <b>function type</b> must be implemented and used with an
<b>optimizer</b>.</p>

<br>
<br>

<b>Function types</b>
<ul>
<li><a href="#type_arbitrary">Arbitrary functions</a></li>
<li><a href="#type_differentiable">Differentiable functions</a>
<ul><li><a href="#type_partially_differentiable">Partially differentiable functions</a></li></ul></li>
<li><a href="#type_separable">Arbitrary separable functions</a></li>
<li><a href="#type_differentiable_separable">Differentiable separable functions</a>
<ul><li><a href="#type_sparse_differentiable_separable">Sparse differentiable separable functions</a></li></ul></li>
<li><a href="#type_categorical">Categorical functions</a></li>
<li><a href="#type_constrained">Constrained functions</a>
<ul><li><a href="#type_sdp">Semidefinite programs</a></li></ul></li>
</ul>

<b>Optimizers</b>
<ul>
<li><a href="#part_adadelta">AdaDelta</a></li>
<li><a href="#part_adagrad">Adagrad</a></li>
<li><a href="#part_adam">Adam, AdaMax, AMSGrad, Nadam, NadaMax, OptimisticAdam</a></li>
<li><a href="#part_bigbatchsgd">Big Batch SGD (BB SGD)</a></li>
<li><a href="#part_cmaes">Covariance Matrix Adaptation Evolution Strategy (CMA-ES)</a></li>
<li><a href="#part_cne">Conventional Neural Evolution (CNE)</a></li>
<li><a href="#part_frankwolfe">Frank-Wolfe (FW)</a></li>
<li><a href="#part_gradientdescent">Gradient Descent (GD)</a></li>
<li><a href="#part_iqn">Incremental Quasi-Newton (IQN)</a></li>
<li><a href="#part_katyusha">Katyusha</a></li>
<li><a href="#part_lbfgs">Limited-memory BFGS (L-BFGS)</a></li>
<li><a href="#part_rmsprop">RMSProp</a></li>
<li><a href="#part_simulatedannealing">Simulated Annealing (SA)</a></li>
<li><a href="#part_sarah">SARAH/SARAH+</a></li>
<li><a href="#part_sgdr">Stochastic Gradient Descent with Restarts (SGDR)</a></li>
<li><a href="#part_snapshotsgdr">Snapshot Stochastic Gradient Descent with Restarts (SnapshotSGDR)</a></li>
<li><a href="#part_smorms3">SMORMS3</a></li>
<li><a href="#part_svrg">Standard stochastic variance reduced gradient (SVRG)</a></li>
<li><a href="#part_spalerasgd">SPALeRA Stochastic Gradient Descent (SPALeRASGD)</a></li>
<li><a href="#part_sgd">Stochastic Gradient Descent (SGD)</a></li>
<a name=""></a>

</ul>

<!-- Arbitrary function CONTENT -->
<a name="type_arbitrary"></a>
<hr class="greyline">
<br>
<br>
<font size=+1><b>Arbitrary functions</b></font>
<br>
<br>
The least restrictive type of function that can be implemented in ensmallen is
a function for which only the objective can be evaluated.  For this, a class
with the following API must be implemented:
<br>
<br>
<!-- todo: add syntax highlighting -->
<pre>
class ArbitraryFunctionType
{
 public:
  // This should return f(x).
  double Evaluate(const arma::mat&amp; x);
};
</pre>
<br>
For this type of function, we assume that the gradient <code>f'(x)</code> is not
computable.  If it is, see <a href="#type_differentiable">differentiable functions</a>.
<br>
<br>
The <code>Evaluate()</code> method is allowed to have additional cv-modifiers
(<code>static</code>,
<code>const</code>, etc.).
<br>
<br>
<a name="type_arbitrary_list"></a>
The following optimizers can be used to optimize an arbitrary function:
<ul>
<li><a href="#part_simulatedannealing">Simulated Annealing</a> (<code>ens::SA<></code>)</li>
<li><a href="#part_cmaes">CMAES</a> (<code>ens::CMAES<></code>)</li>
<li><a href="#part_cne">CNE</a> (<code>ens::CNE<></code>)</li>
</ul>
Each of these optimizers has an <code>Optimize()</code> function that is called as
<code>Optimize(f, x)</code> where <code>f</code> is the function to be optimized (which implements
<code>Evaluate()</code>) and <code>x</code> holds the initial point of the optimization.  After
<code>Optimize()</code> is called, <code>x</code> will hold the final result of the optimization
(that is, the best <code>x</code> found that minimizes <code>f(x)</code>).
<br>
<br>
An example program that implements the objective function f(x) = 2 |x|^2 is
shown below, using the simulated annealing optimizer.
<br>
<br>
<pre>
#include &lt;ensmallen&gt;

class SquaredFunction
{
 public:
  // This returns f(x) = 2 |x|^2.
  double Evaluate(const arma::mat&amp; x)
  {
    return 2 * std::pow(arma::norm(x), 2.0);
  }
};

int main()
{
  // The minimum is at x = [0 0 0].  Our initial point is chosen to be
  // [1.0, -1.0, 1.0].
  arma::mat x("1.0 -1.0 1.0");

  // Create simulated annealing optimizer with default options.
  // The ens::SA&lt;&gt; type can be replaced with any suitable ensmallen optimizer
  // that is able to handle arbitrary functions.
  ens::SA&lt;&gt; optimizer;
  SquaredFunction f; // Create function to be optimized.
  optimizer.Optimize(f, x);

  std::cout &lt;&lt; "Minimum of squared function found with simulated annealing is "
      &lt;&lt; x;
}
</pre>
<br>

<!-- Differentiable function CONTENT -->
<a name="type_differentiable"></a>
<hr class="greyline">
<br>
<br>
<font size=+1><b>Differentiable functions</b></font>
<br>
<br>
Probably the most common type of function that can be optimized with ensmallen
is a differentiable function, where both <code>f(x)</code> and
<code>f'(x)</code> can be calculated.  To optimize a differentiable function
with ensmallen, a class must be implemented that follows the API below:
<br>
<pre>
class DifferentiableFunctionType
{
 public:
  // Given parameters x, return the value of f(x).
  void Evaluate(const arma::mat&amp; x);

  // Given parameters x and a matrix g, store f'(x) in the provided matrix g.
  // g should have the same size (rows, columns) as x.
  void Gradient(const arma::mat&amp; x, arma::mat&amp; gradient);

  // OPTIONAL: this may be implemented in addition to---or instead
  // of---Evaluate() and Gradient().  If this is the only function implemented,
  // implementations of Evaluate() and Gradient() will be automatically
  // generated using template metaprogramming.  Often, implementing
  // EvaluateWithGradient() can result in more efficient optimizations.
  //
  // Given parameters x and a matrix g, return the value of f(x) and store
  // f'(x) in the provided matrix g.  g should have the same size (rows,
  // columns) as x.
  double EvaluateWithGradient(const arma::mat&amp; x, arma::mat&amp; g);
};
</pre>
<br>
<br>
Note that you may implement <b>either</b> <code>Evaluate()</code> and
<code>Gradient()</code> <b>or</b>
<code>EvaluateWithGradient()</code>, but it is not mandatory to implement both.  (Of
course, supplying both is okay too.)  It often results in faster code when
<code>EvaluateWithGradient()</code> is implemented, especially for functions where f(x)
and f'(x) compute some of the same intermediate quantities.
<br>
<br>
Each of the implemented methods is allowed to have additional cv-modifiers
(<code>static</code>, <code>const</code>, etc.).
<br>
<br>
The following optimizers can be used with differentiable functions:
<ul>
<li><a href="#part_lbfgs">L-BFGS</a> (<code>ens::L_BFGS</code>)</li>
<li><a href="#part_frankwolfe">FrankWolfe</a> (<code>ens::FrankWolfe</code>)</li>
<li><a href="#part_gradientdescent">GradientDescent</a>
(<code>ens::GradientDescent</code>)</li>
<li><a href="#part_cne">CNE</a> (<code>ens::CNE</code>)</li>
</ul>
Each of these optimizers has an <code>Optimize()</code> function that is called as
<code>Optimize(f, x)</code> where <code>f</code> is the function to be optimized and <code>x</code> holds the
initial point of the optimization.  After <code>Optimize()</code> is called, <code>x</code> will hold
the final result of the optimization (that is, the best <code>x</code> found that
minimizes <code>f(x)</code>).
<br><br>
<a name="type_differentiable_example"></a>
An example program is shown below.  In this program, we optimize a linear
regression model.  In this setting, we have some matrix <code>data</code> of data points
that we've observed, and some vector <code>responses</code> of the observed responses to
this data.  In our model, we assume that each response is the result of a
weighted linear combination of the data:
<br>
<pre>
  response_i = x * data_i
</pre>
<br>
where <code>x</code> is a vector of parameters.  This gives the objective
function <code>f(x) = (responses - x' data)^2</code>.
<br>
<br>
In the example program, we optimize this objective function and compare the
runtime of an implementation that uses <code>Evaluate()</code> and <code>Gradient()</code>, and the
runtime of an implementation that uses <code>EvaluateWithGradient()</code>.
<br>
<br>
<pre>
#include &lt;ensmallen&gt;

// Define a differentiable objective function by implementing both Evaluate()
// and Gradient() separately.
class LinearRegressionFunction
{
 public:
  // Construct the object with the given data matrix and responses.
  LinearRegressionFunction(const arma::mat&amp; dataIn,
                           const arma::rowvec&amp; responsesIn) :
      data(dataIn), responses(responsesIn) { }

  // Return the objective function for model parameters x.
  double Evaluate(const arma::mat&amp; x)
  {
    return std::pow(arma::norm(responses - x.t() * data), 2.0);
  }

  // Compute the gradient for model parameters x.
  void Gradient(const arma::mat&amp; x, arma::mat&amp; g)
  {
    g = -2 * data * (responses - x.t() * data);
  }

 private:
  // The data.
  const arma::mat&amp; data;
  // The responses to each data point.
  const arma::rowvec&amp; responses;
};

// Define the same function, but only implement EvaluateWithGradient().
class LinearRegressionEWGFunction
{
 public:
  // Construct the object with the given data matrix and responses.
  LinearRegressionEWGFunction(const arma::mat&amp; dataIn,
                              const arma::rowvec&amp; responsesIn) :
      data(dataIn), responses(responsesIn) { }

  // Simultaneously compute both the objective function and gradient for model
  // parameters x.  Note that this is faster than implementing Evaluate() and
  // Gradient() individually because it caches the computation of
  // (responses - x.t() * data)!
  double EvaluateWithGradient(const arma::mat&amp; x, arma::mat&amp; g)
  {
    const arma::rowvec v = (responses - x.t() * data);
    g = -2 * data * v;
    return arma::accu(v % v); // equivalent to \| v \|^2
  }
};

int main()
{
  // We'll run a simple speed comparison between both objective functions.

  // First, generate some random data, with 10000 points and 10 dimensions.
  // This data has no pattern and as such will make a model that's not very
  // useful---but the purpose here is just demonstration. :)
  //
  // For a more "real world" situation, load a dataset from file using X.load()
  // and y.load() (but make sure the matrix is column-major, so that each
  // observation/data point corresponds to a *column*, *not* a row.
  arma::mat data(10, 10000, arma::fill::randn);
  arma::rowvec responses(10000, arma::fill::randn);

  // Create a starting point for our optimization randomly.  The model has 10
  // parameters, so the shape is 10x1.
  arma::mat startingPoint(10, 1, arma::fill::randn);

  // We'll use Armadillo's wall_clock class to do a timing comparison.
  arma::wall_clock clock;

  // Construct the first objective function.
  LinearRegressionFunction lrf1(data, responses);
  arma::mat lrf1Params(startingPoint);

  // Create the L_BFGS optimizer with default parameters.
  // The ens::L_BFGS type can be replaced with any ensmallen optimizer that can
  // handle differentiable functions.
  ens::L_BFGS lbfgs;

  // Time how long L-BFGS takes for the first Evaluate() and Gradient()
  // objective function.
  clock.tic();
  lbfgs.Optimize(lrf1, lrf1Params);
  const double time1 = clock.toc();

  std::cout &lt;&lt; "LinearRegressionFunction with Evaluate() and Gradient() took "
    &lt;&lt; time1 &lt;&lt; " seconds to converge to the model: " &lt;&lt; std::endl;
  std::cout &lt;&lt; lrf1Params.t();

  // Create the second objective function, which uses EvaluateWithGradient().
  LinearRegressionEWGFunction lrf2(data, responses);
  arma::mat lrf2Params(startingPoint);
  // Time how long L-BFGS takes for the EvaluateWithGradient() objective
  // function.
  clock.tic();
  lbfgs.Optimize(lrf2, lrf2Params);
  const double time2 = clock.toc();

  std::cout &lt;&lt; "LinearRegressionEWGFunction with EvaluateWithGradient() took "
    &lt;&lt; time2 &lt;&lt; " seconds to converge to the model: " &lt;&lt; std::endl;
  std::cout &lt;&lt; lrf2Params.t();

  // When this runs, the output parameters will be exactly on the same, but the
  // LinearRegressionEWGFunction will run more quickly!
}
</pre>
<br>
<br>

<!-- Partially differentiable function CONTENT -->
<!-- really this should be a subsection -->
<a name="type_partially_differentiable"></a>
<hr class="greyline">
<br>
<br>
<font size=+1><b>Partially differentiable functions</b></font>
<br>
<br>
Some differentiable functions have the additional property that the gradient
<code>f'(x)</code> can be decomposed along a different axis <code>j</code> such that the gradient is
sparse.  This makes the most sense in machine learning applications where the
function <code>f(x)</code> is being optimized for some dataset <code>data</code>, which has <code>d</code>
dimensions.  A partially differentiable separable function is partially
differentiable with respect to each dimension <code>j</code> of <code>data</code>.  This property is
useful for coordinate descent type algorithms.
<br>
<br>
To use ensmallen optimizers to minimize these types of functions, only two
functions needs to be added to the differentiable function type:
<br>
<pre>
// Compute the partial gradient f'_j(x) with respect to data coordinate j and
// store it in the sparse matrix g.
void Gradient(const arma::mat&amp; x, const size_t j, arma::sp_mat&amp; g);

// Get the number of features that f(x) can be partially differentiated with.
size_t NumFeatures();
</pre>
<br>
<b>Note</b>: many partially differentiable function optimizers do not require a
regular implementation of the <code>Gradient()</code>, so that function may be omitted.
<br>
<br>
If these functions are implemented, the following partially differentiable
function optimizers can be used:
<ul>
<li><a href="#part_scd">Stochastic coordinate descent (SCD)</a>
(<code>ens::SCD&lt;&gt;</code>)</a></li>
</ul>
<br>
<br>

<!-- Arbitrary separable function CONTENT -->
<a name="type_separable"></a>
<hr class="greyline">
<br>
<br>
<font size=+1><b>Arbitrary separable functions</b></font>
<br>
<br>
Often, an objective function <code>f(x)</code> may be represented as the sum of many
functions:
<br>
<pre>
f(x) = f_0(x) + f_1(x) + ... + f_N(x).
</pre>
<br>
<br>
In this function type, we assume the gradient <code>f'(x)</code> is not computable.  If it
is, see <a href="#type_differentiable_separable">Differentiable separable
functions</a>.
<br>
<br>
For machine learning tasks, the objective function may be, e.g., the sum of a
function taken across many data points.  Implementing an arbitrary separable
function type in ensmallen is similar to implementing an arbitrary objective
function, but with a few extra utility methods:
<br>
<pre>
class ArbitrarySeparableFunctionType
{
 public:
  // Given parameters x, return the sum of the individual functions
  // f_i(x) + ... + f_{i + batchSize - 1}(x).  i will always be greater than 0,
  // and i + batchSize will be less than or equal to the value of
  // NumFunctions().
  double Evaluate(const arma::mat&amp; x, const size_t i, const size_t batchSize);

  // Shuffle the ordering of the functions f_i(x).
  // (For machine learning problems, this would be equivalent to shuffling the
  // data points, e.g., before an epoch of learning.)
  void Shuffle();

  // Get the number of functions f_i(x).
  // (For machine learning problems, this is often just the number of points in
  // the dataset.)
  size_t NumFunctions();
};
</pre>
<br>
Each of the implemented methods is allowed to have additional cv-modifiers
(<code>static</code>, <code>const</code>, etc.).
<br>
<br>
<a name="type_separable_list"></a>
The following optimizers can be used with arbitrary separable functions:
<ul>
<li><a href="#part_cmaes">CMAES</a> (<code>ens::CMAES</code>)</li>
<li>any (non-separable) <a href="#type_arbitrary_list">arbitrary function
optimizer</a></li>
</ul>
Each of these optimizers has an <code>Optimize()</code> function that is called as
<code>Optimize(f, x)</code> where <code>f</code> is the function to be optimized and <code>x</code> holds the
initial point of the optimization.  After <code>Optimize()</code> is called, <code>x</code> will hold
the final result of the optimization (that is, the best <code>x</code> found that
minimizes <code>f(x)</code>).
<br>
<br>
<b>Note</b>: using an arbitrary non-separable function optimizer will call
<code>Evaluate(x, 0, NumFunctions() - 1)</code>; if this is a very computationally
intensive operation for your objective function, it may be best to avoid using
a non-separable arbitrary function optimizer.
<br>
<br>
<b>Note</b>: if possible, it's often better to try and use a gradient-based
approach.  See <a href="#type_differentiable_separable">Differentiable separable
functions</a>
for separable <code>f(x)</code> where the gradient <code>f'(x)</code> can be computed.
<br>
<br>
The example program below demonstrates the implementation and use of an
arbitrary separable function.  The function used is the linear regression
objective function, described in <a href="#type_differentiable_example">Differentiable functions</a>.
Given some dataset <code>data</code> and responses <code>responses</code>, the linear regression
objective function is separable as
<pre>
f_i(x) = (responses(i) - x' * data(i))^2
</pre>
where <code>data(i)</code> represents the data point indexed by <code>i</code> and <code>responses(i)</code>
represents the observed response indexed by <code>i</code>.
<br>
<pre>
#include &lt;ensmallen&gt;

// This class implements the linear regression objective function as an
// arbitrary separable function type.
class LinearRegressionFunction
{
 public:
  // Create the linear regression function with the given data and the given
  // responses.
  LinearRegressionFunction(const arma::mat&amp; dataIn,
                           const arma::rowvec&amp; responsesIn) :
      data(data), responses(responses) { }

  // Given parameters x, compute the sum of the separable objective
  // functions starting with f_i(x) and ending with
  // f_{i + batchSize - 1}(x).
  double Evaluate(const arma::mat&amp; x, const size_t i, const size_t batchSize)
  {
    // A more complex implementation could avoid the for loop and use
    // submatrices, but it is easier to understand when implemented this way.
    double objective = 0.0;
    for (size_t j = i; j &lt; i + batchSize; ++j)
    {
      objective += std::pow(responses[j] - x.t() * data.col(j), 2.0);
    }
  }

  // Shuffle the ordering of the functions f_i(x).  We do this by simply
  // shuffling the data and responses.
  void Shuffle()
  {
    // Generate a random ordering of data points.
    arma::uvec ordering = arma::shuffle(
        arma::linspace&lt;arma::uvec&gt;(0, data.n_cols - 1, data.n_cols));

    // This reorders the data and responses with our randomly-generated
    // ordering above.
    data = data.cols(ordering);
    responses = responses.cols(ordering);
  }

  // Return the number of functions f_i(x).  In our case this is simply the
  // number of data points.
  size_t NumFunctions() { return data.n_cols; }
};

int main()
{
  // First, generate some random data, with 10000 points and 10 dimensions.
  // This data has no pattern and as such will make a model that's not very
  // useful---but the purpose here is just demonstration. :)
  //
  // For a more "real world" situation, load a dataset from file using X.load()
  // and y.load() (but make sure the matrix is column-major, so that each
  // observation/data point corresponds to a *column*, *not* a row.
  arma::mat data(10, 10000, arma::fill::randn);
  arma::rowvec responses(10000, arma::fill::randn);

  // Create a starting point for our optimization randomly.  The model has 10
  // parameters, so the shape is 10x1.
  arma::mat params(10, 1, arma::fill::randn);

  // Use the CMAES optimizer with default parameters to minimize the
  // LinearRegressionFunction.
  // The ens::CMAES type can be replaced with any suitable ensmallen optimizer
  // that can handle arbitrary separable functions.
  ens::CMAES cmaes;
  LinearRegressionFunction lrf(data, responses);
  cmaes.Optimize(lrf, params);

  std::cout &lt;&lt; "The optimized linear regression model found by CMAES has the "
      &lt;&lt; "parameters " &lt;&lt; params.t();
}
</pre>
<br>
<br>

<!-- Separable function CONTENT -->
<a name="type_differentiable_separable"></a>
<hr class="greyline">
<br>
<br>
<font size=+1><b>Differentiable separable functions</b></font>
<br>
<br>
Likely the most important type of function to be optimized in machine learning
and some other fields is the differentiable separable function.  A
differentiable separable function f(x) can be represented as the sum of many
functions:
<br>
<pre>
f(x) = f_0(x) + f_1(x) + ... + f_N(x).
</pre>
<br>
And it also has a computable separable gradient <code>f'(x)</code>:
<br>
<pre>
f'(x) = f'_0(x) + f'_1(x) + ... + f'_N(x).
</pre>
<br>
For machine learning tasks, the objective function may be, e.g., the sum of a
function taken across many data points.  Implementing a differentiable
separable function type in ensmallen is similar to implementing an ordinary
differentiable function, but with a few extra utility methods:
<br>
<pre>
class DifferentiableSeparableFunctionType
{
 public:
  // Given parameters x, return the sum of the individual functions
  // f_i(x) + ... + f_{i + batchSize - 1}(x).  i will always be greater than 0,
  // and i + batchSize will be less than or equal to the value of
  // NumFunctions().
  double Evaluate(const arma::mat&amp; x, const size_t i, const size_t batchSize);

  // Given parameters x and a matrix g, store the sum of the gradient of
  // individual functions f'_i(x) + ... + f'_{i + batchSize - 1}(x) into g.  i
  // will always be greater than 0, and i + batchSize will be less than or
  // equal to the value of NumFunctions().
  void Gradient(const arma::mat&amp; x,
                const size_t i,
                arma::mat&amp; g,
                const size_t batchSize);

  // Shuffle the ordering of the functions f_i(x).
  // (For machine learning problems, this would be equivalent to shuffling the
  // data points, e.g., before an epoch of learning.)
  void Shuffle();

  // Get the number of functions f_i(x).
  // (For machine learning problems, this is often just the number of points in
  // the dataset.)
  size_t NumFunctions();

  // OPTIONAL: this may be implemented in addition to---or instead
  // of---Evaluate() and Gradient().  If this is the only function implemented,
  // implementations of Evaluate() and Gradient() will be automatically
  // generated using template metaprogramming.  Often, implementing
  // EvaluateWithGradient() can result in more efficient optimizations.
  //
  // Given parameters x and a matrix g, return the sum of the individual
  // functions f_i(x) + ... + f_{i + batchSize - 1}(x), and store the sum of
  // the gradient of individual functions f'_i(x) + ... +
  // f'_{i + batchSize - 1}(x) into the provided matrix g.  g should have the
  // same size (rows, columns) as x.  i will always be greater than 0, and i +
  // batchSize will be less than or equal to the value of NumFunctions().
  double EvaluateWithGradient(const arma::mat&amp; x,
                              const size_t i,
                              arma::mat&amp; g,
                              const size_t batchSize);
};
</pre>
<br>
Note that you may implement <b>either</b> <code>Evaluate()</code> and
<code>Gradient()</code> <b>or</b>
<code>EvaluateWithGradient()</code>, but it is not mandatory to implement both.  (Of
course, supplying both is okay too.)  It often results in faster code when
<code>EvaluateWithGradient()</code> is implemented, especially for functions
where <code>f(x)</code>
and <code>f'(x)</code> compute some of the same intermediate quantities.
<br>
<br>
Each of the implemented methods is allowed to have additional cv-modifiers
(<code>static</code>, <code>const</code>, etc.).
<br>
<br>
The following optimizers can be used with differentiable functions:
<ul>
<li><a href="#type_sgd">Stochastic gradient descent (SGD)</a>
(<code>ens::SGD&lt;&gt;</code>)</li>
<li><a href="#type_adam">Adam</a> (<code>ens::Adam&lt;&gt;</code>)</li>
<li><a href="#type_adagrad">AdaGrad</a> (<code>ens::AdaGrad&lt;&gt;</code>)</li>
<li><a href="#type_adadelta">AdaDelta</a> (<code>ens::AdaDelta&lt;&gt;</code>)</li> 
<li><a href="#type_katyusha">Katyusha</a> (<code>ens::Katyusha</code>)</li>
<li><a href="#type_rmsprop">RMSprop</a> (<code>ens::RMSProp&lt;&gt;</code>)</li>
<li><a href="#type_sgdr">SGD with restarts (SGDR)</a> (<code>ens::SGDR&lt;&gt;</code>)</li>
<li><a href="#type_smorms3">SMORMS3</a> (<code>ens::SMORMS3&lt;&gt;</code>)</li>
<li>TODO: add more...</li>
<li>any (non-separable) <a href="#type_differentiable_list">differentiable function optimizer</a></li>
<li>any (non-differentiable) <a href="#type_arbitrary_list">separable arbitrary optimizer</a></li>
</ul>
<b>Note</b>: using a non-separable differentiable function optimizer
will call <code>Evaluate(x, 0, NumFunctions() - 1)</code> and <code>Gradient(x, 0 g,
NumFunctions() - 1)</code>; if this is a very computationally intensive operation for
your objective function, it may be best to avoid using a differentiable
function optimizer.
<br>
<br>
The example program below demonstrates the implementation and use of an
arbitrary separable function.  The function used is the linear regression
objective function, described in <a href="#type_differentiable_example">Differentiable functions</a>.
Given some dataset <code>data</code> and responses <code>responses</code>, the linear regression
objective function is separable as
<br>
<pre>
f_i(x) = (responses(i) - x' * data(i))^2
</pre>
<br>
where <code>data(i)</code> represents the data point indexed by <code>i</code> and <code>responses(i)</code>
represents the observed response indexed by <code>i</code>.  This example implementation
only implements <code>EvaluateWithGradient()</code> in order to avoid redundant
calculations.

<pre>
#include &lt;ensmallen&gt;

// This class implements the linear regression objective function as an
// arbitrary separable function type.
class LinearRegressionFunction
{
 public:
 // Create the linear regression function with the given data and the given
  // responses.
  LinearRegressionFunction(const arma::mat&amp; dataIn,
                           const arma::rowvec&amp; responsesIn) :
      data(data), responses(responses) { }

  // Given parameters x, compute the sum of the separable objective
  // functions starting with f_i(x) and ending with
  // f_{i + batchSize - 1}(x), and also compute the gradient of those functions
  // and store them in g.
  void EvaluateWithGradient(const arma::mat&amp; x,
                            const size_t i,
                            arma::mat&amp; g,
                            const size_t batchSize)
  {
    // This slightly complex implementation uses Armadillo submatrices to
    // compute the objective functions and gradients simultaneously for
    // multiple points.
    //
    // The shared computation between the objective and gradient is the term
    // (response - x * data) so we compute that first, only for points in the
    // batch.
    const arma::rowvec v = (responses.cols(i, i + batchSize - 1) - x.t() *
        data.cols(i, i + batchSize - 1));
    g = -2 * data.cols(i, i + batchSize - 1) * v;
    return arma::accu(v % v); // equivalent to |v|^2
  }

  // Shuffle the ordering of the functions f_i(x).  We do this by simply
  // shuffling the data and responses.
  void Shuffle()
  {
    // Generate a random ordering of data points.
    arma::uvec ordering = arma::shuffle(
        arma::linspace&lt;arma::uvec&gt;(0, data.n_cols - 1, data.n_cols));

    // This reorders the data and responses with our randomly-generated
    // ordering above.
    data = data.cols(ordering);
    responses = responses.cols(ordering);
  }
  // Return the number of functions f_i(x).  In our case this is simply the
  // number of data points.
  size_t NumFunctions() { return data.n_cols; }
};

int main()
{
  // First, generate some random data, with 10000 points and 10 dimensions.
  // This data has no pattern and as such will make a model that's not very
  // useful---but the purpose here is just demonstration. :)
  //
  // For a more "real world" situation, load a dataset from file using X.load()
  // and y.load() (but make sure the matrix is column-major, so that each
  // observation/data point corresponds to a *column*, *not* a row.
  arma::mat data(10, 10000, arma::fill::randn);
  arma::rowvec responses(10000, arma::fill::randn);

  // Create a starting point for our optimization randomly.  The model has 10
  // parameters, so the shape is 10x1.
  arma::mat params(10, 1, arma::fill::randn);

  // Use RMSprop to find the best parameters for the linear regression model.
  // The type 'ens::RMSprop' can be changed for any ensmallen optimizer able to
  // handle differentiable separable functions.
  ens::RMSprop rmsprop;
  LinearRegressionFunction lrf(data, responses);
  rmsprop.Optimize(lrf, params);

  std::cout &lt;&lt; "The optimized linear regression model found by RMSprop has the"
      &lt;&lt; " parameters " &lt;&lt; params.t();
}
</pre>
<br>
<br>

<!-- Sparse differentiable separable CONTENT -->
<a name="type_sparse_differentiable_separable"></a>
<hr class="greyline">
<br>
<br>
<font size=+1><b>Sparse differentiable separable functions</b></font>
<br>
<br>
Some differentiable separable functions have the additional property that
the gradient <code>f'_i(x)</code> is sparse.  When this is true, one additional
method can be implemented as part of the class to be optimized:
<br>
<pre>
// Add this definition to use sparse differentiable separable function
// optimizers.  Given x, store the sum of the sparse gradient f'_i(x) + ... +
// f'_{i + batchSize - 1}(x) into the provided matrix g.
void Gradient(const arma::mat&amp; x,
              const size_t i,
              arma::sp_mat&amp; g,
              const size_t batchSize);
</pre>
<br>
It's also possible to instead use templates to provide only one <code>Gradient()</code>
function for both sparse and non-sparse optimizers:
<br>
<pre>
// This provides Gradient() for both sparse and non-sparse optimizers.
template&lt;typename GradType&gt;
void Gradient(const arma::mat&amp; x,
              const size_t i,
              GradType&amp; g,
              const size_t batchSize);
</pre>
<br>
If either of these methods are available, then any ensmallen optimizer that
optimizes sparse separable differentiable functions may be used.  This
includes:
<ul>
<li><a href="#type_parallelsgd">Parallel SGD (Hogwild!)</a> (<code>ens::ParallelSGD</code>)</li>
</ul>
<br>
<br>

<!-- Categorical function CONTENT -->
<a name="type_categorical"></a>
<hr class="greyline">
<br>
<br>
<font size=+1><b>Categorical functions</b></font>
<br>
<br>
A categorical function is a function <code>f(x)</code> where some of the values of x are
categorical variables (i.e. they take integer values <code>[0, c - 1]</code> and each value
<code>0, 1, ..., c - 1</code> is unrelated).  In this situation, the function is not
differentiable, and so only the objective f(x) can be implemented.  Therefore
the class requirements for a categorical function are exactly the same as for
an <code>ArbitraryFunctionType</code>---but for any categorical dimension
<code>x_i</code> in <code>x</code>, the
value will be in the range <code>[0, c_i - 1]</code> where <code>c_i</code> is the number of categories
in dimension <code>x_i</code>.
<br>
<pre>
class CategoricalFunction
{
 public:
  // Return the objective function for the given parameters x.
  double Evaluate(const arma::mat&amp; x);
};
</pre>
<br>
However, when an optimizer's <code>Optimize()</code> method is called, two additional
parameters must be specified, in addition to the function to optimize and the
matrix holding the parameters:
<br>
<ul>
<li><code>const std::vector&lt;bool&gt;&amp; categoricalDimensions</code>: a vector of length equal
to the number of elements in <code>x</code> (the number of dimensions).  If an element
is true, then the dimension is categorical.</li>
<li><code>const arma::Row&lt;size_t&gt;&amp; numCategories</code>: a vector of length equal to the
number of elements in <code>x</code> (the number of dimensions).  If a dimension is
categorical, then the corresponding value in <code>numCategories</code> should hold the
number of categories in that dimension.</li>
</ul>
The following optimizers can be used in this way to optimize a categorical
function:
<ul>
<li><a href="#part_gridsearch">Grid search</a> (all parameters must be
categorical) (<code>ens::GridSearch</code>)</li>
</ul>
An example program showing usage of categorical optimization is shown below.
<br>
<pre>
#include &lt;ensmallen&rt;

// An implementation of a simple categorical function.  The parameters can be
// understood as x = [c1 c2 c3].  When c1 = 0, c2 = 2, and c3 = 1, the value of
// f(x) is 0.  In any other case, the value of f(x) is 10.  Therefore, the
// optimum is found at [0, 2, 1].
class SimpleCategoricalFunction
{
 public:
  // Return the objective function f(x) as described above.
  double Evaluate(const arma::mat&amp; x)
  {
    if (size_t(x[0]) == 0 &amp;&amp;
        size_t(x[1]) == 2 &amp;&amp;
        size_t(x[2]) == 1)
      return 0.0;
    else
      return 10.0;
  }
};

int main()
{
  // Create and optimize the categorical function with the GridSearch
  // optimizer.  We must also create a std::vector<bool> that holds the types
  // of each dimension, and an arma::Row<size_t> that holds the number of
  // categories in each dimension.
  CategoricalFunction c;

  // We have three categorical dimensions only.
  std::vector&lt;bool&gt; categoricalDimensions;
  categoricalDimensions.push_back(true);
  categoricalDimensions.push_back(true);
  categoricalDimensions.push_back(true);

  // The first category can take 5 values; the second can take 3; the third can
  // take 12.
  arma::Row&lt;size_t&gt; numCategories("5 3 12");

  // The initial point for our optimization will be to set all categories to 0.
  arma::mat params("0 0 0");
  // Now create the GridSearch optimizer with default parameters, and run the
  // optimization.
  // The ens::GridSearch type can be replaced with any ensmallen optimizer that
  // is able to handle categorical functions.
  ens::GridSearch gs;
  gs.Optimize(c, params, categoricalDimensions, numCategories);

  std::cout &lt;&lt; "The ens::GridSearch optimizer found the optimal parameters to "
      &lt;&lt; "be " &lt;&lt; params;
}
</pre>
<br>
<br>

<!-- Constrained function CONTENT -->
<a name="type_constrained"></a>
<hr type="greyline">
<br>
<br>
<font size=+1><b>Constrained functions</b></font>
<br>
<br>
A constrained function is an objective function <code>f(x)</code> that is also subject to
some constraints on <code>x</code>.  (For instance, perhaps a constraint could be that <code>x</code>
is a positive semidefinite matrix.)  ensmallen is able to handle differentiable
objective functions of this type---so, <code>f'(x)</code> must also be computable.  Given
some set of constraints <code>c_0(x), ... c_M(x)</code>, we can re-express our constrained
objective function as
<br>
<pre>
f_C(x) = f(x) + c_0(x) + ... + c_M(x)
</pre>
<br>
where the constraint <code>c_i(x)</code> is <code>DBL_MAX</code> if it is not satisfied, and
otherwise takes some real value.  For a "hard constraint", we can simply take
<code>c_i(x) = 0</code> when it is satisfied.  But allowing <code>c_i(x)</code> to return anything
allows us to handle "soft" constraints also.
<br>
<br>
In order to optimize a constrained function with ensmallen, a class
implementing the API below is required.
<br>
<pre>
class ConstrainedFunctionType
{
 public:
  // Return the objective function f(x) for the given x.
  double Evaluate(const arma::mat&amp; x);

  // Compute the gradient of f(x) for the given x and store the result in g.
  void Gradient(const arma::mat&amp; x, arma::mat&amp; g);

  // Get the number of constraints on the objective function.
  size_t NumConstraints();

  // Evaluate constraint i at the parameters x.  If the constraint is
  // unsatisfied, DBL_MAX should be returned.  If the constraint is satisfied,
  // any real value can be returned.  The optimizer will add this value to its
  // overall objective that it is trying to minimize.  (So, a hard constraint
  // can just return 0 if it's satisfied.)
  double EvaluateConstraint(const size_t i, const arma::mat&amp; x);
  // Evaluate the gradient of constraint i at the parameters x, storing the
  // result in the given matrix g.  If this is a hard constraint you can set
  // the gradient to 0.  If the constraint is not satisfied, it could be
  // helpful to set the gradient in such a way that the gradient points in the
  // direction where the constraint would be satisfied.
  double GradientConstraint(const size_t i, const arma::mat&amp; x, arma::mat&amp; g);
};
</pre>
<br>
A constrained function can be optimized with the following optimizers:
<ul>
<li><a href="#part_auglagrangian">Augmented Lagrangian</a> (<code>ens::AugLagrangian</code>)</li>
</ul>
<br>
<br>

<!-- Semidefinite program CONTENT -->
<a name="type_sdp"></a>
<hr class="greyline">
<br>
<br>
<font size=+1><b>Semidefinite programs</b></font>
<br>
<br>
A special class of constrained function is a semidefinite program.  ensmallen
has support for creating and optimizing semidefinite programs via the
<code>ens::SDP&lt;&gt;</code> class.  For this, the SDP must be expressed in the primal form:
<br>
<pre>
min_x dot(C, x) such that

dot(A_i, x) = b_i, for i = 1, ..., M;
x >= 0
</pre>
<br>
In this case, <code>A_i</code> and <code>C</code> are square matrices (sparse or dense), and <code>b_i</code> is
a scalar.
<br>
<br>
Once the problem is expressed in this form, a class of type
<code>ens::SDP&lt;&gt;</code> can be
created.  <code>SDP&lt;arma::mat&gt;</code> indicates an SDP with a dense C, and
<code>SDP&lt;arma::sp_mat&gt;</code> indicates an SDP with a sparse C.  The class has the
following useful methods:
<ul>
<li><code>SDP(cMatrixSize, numDenseConstraints, numSparseConstraints)</code>: create a new
   <code>SDP</code></li>
<li><code>size_t NumSparseConstraints()</code>: get number of sparse constraint
   matrices <code>A_i</code></li>
<li><code>size_t NumDenseConstraints()</code>: get number of dense constraint
   matrices <code>A_i</code></li>
<li><code>std::vector&lt;arma::mat&gt;&amp; DenseA()</code>: get vector of dense
   <code>A_i</code> matrices</li>
<li><code>std::vector&lt;arma::sp_mat&gt;&amp; SparseA()</code>: get vector of sparse
   <code>A_i</code> matrices</li>
<li><code>arma::vec&amp; DenseB()</code>: get vector of <code>b_i</code> values
   for dense <code>A_i</code> constraints</li>
<li><code>arma::vec&amp; SparseB()</code>: get vector of <code>b_i</code> values
   for sparse <code>A_i</code> constraints</li>
</il>
Once these methods are used to set each <code>A_i</code> matrix and
corresponding <code>b_i</code> value,
and <code>C</code> objective matrix, the SDP object can be used with any ensmallen SDP
solver.  The list of SDP solvers is below:
<ul>
<li><a href="#part_primaldualsolver">Primal-dual SDP solver</a>
(<code>ens::PrimalDualSolver</code>)</li>
<li><a href="#part_lrsdp">Low-rank accelerated SDP solver</a>
(<code>ens::LRSDP</code>)</li>
</ul>

Example code showing how to solve an SDP is given below.
<br>
<pre>
#include &lt;ensmallen&gt;

int main()
{
  // We will build a toy semidefinite program and then use the PrimalDualSolver
  // to find a solution

  // The semi-definite constraint looks like:
  //
  // [ 1  x_12  x_13  0  0  0  0 ]
  // [     1    x_23  0  0  0  0 ]
  // [            1   0  0  0  0 ]
  // [               s1  0  0  0 ]  &gt;= 0
  // [                  s2  0  0 ]
  // [                     s3  0 ]
  // [                        s4 ]

  // x_11 == 0
  arma::sp_mat A0(7, 7); A0.zeros();
  A0(0, 0) = 1.;

  // x_22 == 0
  arma::sp_mat A1(7, 7); A1.zeros();
  A1(1, 1) = 1.;

  // x_33 == 0
  arma::sp_mat A2(7, 7); A2.zeros();
  A2(2, 2) = 1.;

  // x_12 &lt;= -0.1  &lt;==&gt;  x_12 + s1 == -0.1, s1 &gt;= 0
  arma::sp_mat A3(7, 7); A3.zeros();
  A3(1, 0) = A3(0, 1) = 1.; A3(3, 3) = 2.;

  // -0.2 &lt;= x_12  &lt;==&gt;  x_12 - s2 == -0.2, s2 &gt;= 0
  arma::sp_mat A4(7, 7); A4.zeros();
  A4(1, 0) = A4(0, 1) = 1.; A4(4, 4) = -2.;

  // x_23 &lt;= 0.5  &lt;==&gt;  x_23 + s3 == 0.5, s3 &gt;= 0
  arma::sp_mat A5(7, 7); A5.zeros();
  A5(2, 1) = A5(1, 2) = 1.; A5(5, 5) = 2.;

  // 0.4 &lt;= x_23  &lt;==&gt;  x_23 - s4 == 0.4, s4 &gt;= 0
  arma::sp_mat A6(7, 7); A6.zeros();
  A6(2, 1) = A6(1, 2) = 1.; A6(6, 6) = -2.;

  std::vector&lt;arma::sp_mat&gt; ais({A0, A1, A2, A3, A4, A5, A6});

  SDP&lt;arma::sp_mat&gt; sdp(7, 7 + 4 + 4 + 4 + 3 + 2 + 1, 0);

  for (size_t j = 0; j &lt; 3; j++)
  {
    // x_j4 == x_j5 == x_j6 == x_j7 == 0
    for (size_t i = 0; i &lt; 4; i++)
    {
      arma::sp_mat A(7, 7); A.zeros();
      A(i + 3, j) = A(j, i + 3) = 1;
      ais.emplace_back(A);
    }
  }

  // x_45 == x_46 == x_47 == 0
  for (size_t i = 0; i &lt; 3; i++)
  {
    arma::sp_mat A(7, 7); A.zeros();
    A(i + 4, 3) = A(3, i + 4) = 1;
    ais.emplace_back(A);
  }

  // x_56 == x_57 == 0
  for (size_t i = 0; i &lt; 2; i++)
  {
    arma::sp_mat A(7, 7); A.zeros();
    A(i + 5, 4) = A(4, i + 5) = 1;
    ais.emplace_back(A);
  }

  // x_67 == 0
  arma::sp_mat A(7, 7); A.zeros();
  A(6, 5) = A(5, 6) = 1;
  ais.emplace_back(A);

  std::swap(sdp.SparseA(), ais);

  sdp.SparseB().zeros();
  sdp.SparseB()[0] = sdp.SparseB()[1] = sdp.SparseB()[2] = 1.;
  sdp.SparseB()[3] = -0.2; sdp.SparseB()[4] = -0.4;
  sdp.SparseB()[5] = 1.; sdp.SparseB()[6] = 0.8;

  sdp.C().zeros();
  sdp.C()(0, 2) = sdp.C()(2, 0) = 1.;

  // That took a long time but we finally set up the problem right!  Now we can
  // use the PrimalDualSolver to solve it.
  // ens::PrimalDualSolver could be replaced with ens::LRSDP or other ensmallen
  // SDP solvers.
  PrimalDualSolver&lt;SDP&lt;arma::sp_mat&gt;&gt; solver(sdp);
  arma::mat X, Z;
  arma::vec ysparse, ydense;
  // ysparse, ydense, and Z hold the primal and dual variables found during the
  // optimization.
  const double obj = solver.Optimize(X, ysparse, ydense, Z);

  std::cout &lt;&lt; "SDP optimized with objective " &lt;&lt; obj &lt;&lt; "." &lt;&lt; std::endl;
}
</pre>
<br>
<br>


<!-- AdaDelta CONTENT -->
<a name="part_adadelta"></a>
<hr class="greyline">
<br>
<br>
<a name="part_adadelta"></a>
<font size=+1><b>AdaDelta</b></font>
<br>
<br>
Adadelta is an extension of Adagrad that adapts learning rates based on a moving window of gradient updates, instead of accumulating all past gradients. Instead of accumulating all past squared gradients, the sum of gradients is recursively defined as a decaying average of all past squared gradients.
<a name="Attributes"></a>

<br>
<br>
<b>Constructors</b>

<ul>
  <li>AdaDelta(<i>stepSize, batchSize, rho, epsilon, maxIterations, tolerance, shuffle</i>)</li>
  <li>AdaDelta(<i>stepSize, batchSize</i>)</li>
  <li>AdaDelta(<i>stepSize</i>)</li>
</ul>

<b>Attributes</b>

<ul>
<table style="text-align: left;" border="0" cellpadding="0" cellspacing="0">
<tbody>
<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>stepSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Step size for each iteration.</td>
</tr>
<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>batchSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Number of points to process in one step.</td>
</tr>
<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>rho</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Smoothing constant. Corresponding to fraction of gradient to keep at each time step.</td>
</tr>
<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>epsilon</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Value used to initialise the mean squared gradient parameter.</td>
</tr>
<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>maxIterations</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum number of iterations allowed (0 means no limit).</td>
</tr>
<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>tolerance</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum absolute tolerance to terminate algorithm.</td>
</tr>
<tr>
<td><code>bool</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>shuffle</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>If true, the function order is shuffled; otherwise, each function is visited in linear order.</td>
</tr>
</tbody>
</table>
</ul>
<ul>

<br>
<li>Examples:</li>
<ul>
<pre>
AdaDelta optimizer(1.0, 1, 0.99, 1e-8, 1000, 1e-9, true);

RosenbrockFunction f;
arma::mat coordinates = f.GetInitialPoint();
optimizer.Optimize(f, coordinates);
</pre>
</ul>
<li>
See also:
<ul>
<li><a href="https://arxiv.org/abs/1212.5701">Adadelta - an adaptive learning rate method</a></li>
<li><a href="#Adagrad">Adagrad</a></li>
</ul>
</li>
<br>
</ul>

<!-- AdaGrad CONTENT -->
<a name="part_adagrad"></a>
<div class="pagebreak"></div>
<hr class="greyline">
<br>
<br>
<font size=+1><b>Adagrad</b></font>
<br>
<br>
Adagrad is an optimizer with parameter-specific learning rates, which are adapted relative to how frequently a parameter gets updated during training. Larger updates for more sparse parameters and smaller updates for less sparse parameters.
<a name="Attributes"></a>

<br>
<br>
<b>Constructors</b>

<ul>
  <li>Adagrad(<i>stepSize, batchSize, epsilon, maxIterations, tolerance, shuffle</i>)</li>
  <li>Adagrad(<i>stepSize, batchSize</i>)</li>
  <li>Adagrad(<i>stepSize</i>)</li>
</ul>

<b>Attributes</b>
<ul>
<table style="text-align: left;" border="0" cellpadding="0" cellspacing="0">
<tbody>
<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>stepSize</b>(double)</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Step size for each iteration.</td>
</tr>
<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>batchSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Number of points to process in one step.</td>
</tr>
<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>epsilon</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Value used to initialise the mean squared gradient parameter.</td>
</tr>
<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>maxIterations</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum number of iterations allowed (0 means no limit).</td>
</tr>
<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>tolerance</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum absolute tolerance to terminate algorithm.</td>
</tr>
<tr>
<td><code>bool</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>shuffle</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>If true, the function order is shuffled; otherwise, each function is visited in linear order.</td>
</tr>
</tbody>
</table>
</ul>
<ul>

<br>
<li>Examples:</li>
<ul>
<pre>
AdaGrad optimizer(1.0, 1, 1e-8, 1000, 1e-9, true);

RosenbrockFunction f;
arma::mat coordinates = f.GetInitialPoint();
optimizer.Optimize(f, coordinates);
</pre>
</ul>
<li>
See also:
<ul>
<li><a href="http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf">Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</a></li>
<li><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#AdaGrad">AdaGrad in Wikipedia</a></li>
<li><a href="#Adagrad">AdaDelta</a></li>
</ul>
</li>
<br>
</ul>

<!-- Adam CONTENT -->
<a name="part_adam"></a>
<div class="pagebreak"></div>
<hr class="greyline">
<br>
<br>
<font size=+1><b>Adam</b></font>
<br>
<br>
Adam is an optimizer that computes individual adaptive learning rates for different parameters from estimates of first and second moments of the gradients. AdaMax is a variant of Adam based on the infinity norm as given in the section 7 of the following paper. Nadam is an optimizer that combines the Adam and NAG. NadaMax is an variant of Nadam based on infinity form.
<a name="Attributes"></a>

<br>
<br>
<b>Constructors</b>

<ul>
  <li>Adam(<i>stepSize, batchSize, beta1, beta2, eps, maxIterations, tolerance, shuffle</i>)</li>
  <li>Adam(<i>stepSize, batchSize, maxIterations, tolerance, shuffle</i>)</li>
  <li>Adam(<i>stepSize</i>)</li>
</ul>

<b>Attributes</b>
<ul>
<table style="text-align: left;" border="0" cellpadding="0" cellspacing="0">
<tbody>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>stepSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Step size for each iteration.</td>
</tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>batchSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Initial batch size.</td>
</tr>
<tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>beta1</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Exponential decay rate for the first moment estimates.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>beta2</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Exponential decay rate for the weighted infinity norm estimates.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>eps</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Value used to initialise the mean squared gradient parameter.</td>
</tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>maxIterations</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum number of iterations allowed (0 means no limit).</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>tolerance</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum absolute tolerance to terminate algorithm.</td>
</tr>

<tr>
<td><code>bool</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>shuffle</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>If true, the batch order is shuffled; otherwise, each batch is visited in linear order.</td>
</tr>

</tr>
</tbody>
</table>
</ul>
<ul>


<li>For convenience the following typedefs have been defined:</li>

<ul>
<table style="text-align: left;" border="0" cellpadding="2" cellspacing="2">
  <tbody>
    <tr>
      <td style="vertical-align: top; text-align: right;">
      <code>Adam</code>
      </td>
      <td style="vertical-align: top;">
      &nbsp;=&nbsp;
      </td>
      <td style="vertical-align: top;">
      <code>AdamType&lt;AdamUpdate&gt;</code>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top; text-align: right;">
      <code>AdaMax</code>
      </td>
      <td style="vertical-align: top;">
      &nbsp;=&nbsp;
      </td>
      <td style="vertical-align: top;">
      <code>AdamType&lt;AdaMaxUpdate&gt;</code>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top; text-align: right;">
      <code>AMSGrad</code>
      </td>
      <td style="vertical-align: top;">
      &nbsp;=&nbsp;
      </td>
      <td style="vertical-align: top;">
      <code>AdamType&lt;AMSGradUpdate&gt;</code>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top; text-align: right;">
      <code>Nadam</code>
      </td>
      <td style="vertical-align: top;">
      &nbsp;=&nbsp;
      </td>
      <td style="vertical-align: top;">
      <code>AdamType&lt;NadamUpdate&gt;</code>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top; text-align: right;">
      <code>NadaMax</code>
      </td>
      <td style="vertical-align: top;">
      &nbsp;=&nbsp;
      </td>
      <td style="vertical-align: top;">
      <code>AdamType&lt;NadaMaxUpdate&gt;</code>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top; text-align: right;">
      <code>OptimisticAdam</code>
      </td>
      <td style="vertical-align: top;">
      &nbsp;=&nbsp;
      </td>
      <td style="vertical-align: top;">
      <code>AdamType&lt;OptimisticAdamUpdate&gt;</code>
      </td>
    </tr>
  </tbody>
</table>
</ul>

<br>
<li>Examples:</li>
<ul>
<pre>
RosenbrockFunction f;
arma::mat coordinates = f.GetInitialPoint();

Adam optimizer(1e-3, 1, 0.9, 0.999, 1e-8, 500000, 1e-9, true);  // Standard Adam.
optimizer.Optimize(f, coordinates);

AdaMax adaMaxOptimizer(2e-3, 1, 0.9, 0.999, 1e-8, 500000, 1e-9, true); // AdaMax.
adaMaxOptimizer.Optimize(f, coordinates);

AMSGrad amsGradOptimizer(1e-3, 1, 0.9, 0.999, 1e-8, 500000, 1e-11, true);  // AMSGrad.
amsGradOptimizer.Optimize(f, coordinates);

Nadam nadamOptimizer(1e-3, 1, 0.9, 0.99, 1e-8, 500000, 1e-9, true); // Nadam.
nadamOptimizer.Optimize(f, coordinates);

OptimisticAdam optimisticAdamOptimizer(1e-2, 1, 0.9, 0.99, 1e-8); // OptimisticAdam.
optimisticAdamOptimizer.Optimize(f, coordinates);
</pre>
</ul>
<li>
See also:
<ul>
<li><a href="https://arxiv.org/abs/1412.6980">Adam: A Method for Stochastic Optimization</a></li>
<li><a href="https://openreview.net/forum?id=ryQu7f-RZ">On the Convergence of Adam and Beyond</a></li>
<li><a href="https://openreview.net/forum?id=OM0jvwB8jIp57ZJjtNEZ">Incorporating Nesterov momentum into Adam</a></li>
<li><a href="https://arxiv.org/abs/1711.00141">Training GANs with Optimism</a></li>

</ul>
</li>
<br>
</ul>

<!-- Big Batch SGD CONTENT -->
<a name="part_bigbatchsgd"></a>
<div class="pagebreak"></div>
<hr class="greyline">
<br>
<br>
<font size=+1><b>Big Batch SGD</b></font>
<br>
<br>
Big Batch SGD adaptively grows the batch size over time to maintain a nearly constant signal-to-noise ratio in the gradient approximation, so the Big Batch SGD optimizer is able to adaptively adjust batch sizes without user oversight.
<a name="Attributes"></a>

<br>
<br>
<b>Constructors</b>

<ul>
  <li>BigBatchSGD(<i>stepSize, batchSize, epsilon, maxIterations, tolerance, shuffle</i>)</li>
  <li>BigBatchSGD(<i>stepSize, batchSize</i>)</li>
  <li>BigBatchSGD(<i>stepSize</i>)</li>
</ul>

<b>Attributes</b>
<ul>
<table style="text-align: left;" border="0" cellpadding="0" cellspacing="0">
<tbody>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>batchSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Initial batch size.</td>
</tr>
<tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>stepSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Step size for each iteration.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>batchDelta</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Factor for the batch update step.</td>
</tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>maxIterations</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum number of iterations allowed (0 means no limit).</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>tolerance</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum absolute tolerance to terminate algorithm.</td>
</tr>

<tr>
<td><code>bool</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>shuffle</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>If true, the batch order is shuffled; otherwise, each batch is visited in linear order.</td>
</tr>

</tr>
</tbody>
</table>
</ul>
<ul>


<li>For convenience the following typedefs have been defined:</li>

<ul>
<table style="text-align: left;" border="0" cellpadding="2" cellspacing="2">
  <tbody>
    <tr>
      <td style="vertical-align: top; text-align: right;">
      <code>BBS_Armijo</code>
      </td>
      <td style="vertical-align: top;">
      &nbsp;=&nbsp;
      </td>
      <td style="vertical-align: top;">
      <code>BigBatchSGD&lt;BacktrackingLineSearch&gt;</code>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top; text-align: right;">
      <code>BBS_BB</code>
      </td>
      <td style="vertical-align: top;">
      &nbsp;=&nbsp;
      </td>
      <td style="vertical-align: top;">
      <code>BigBatchSGD&lt;AdaptiveStepsize&gt;</code>
      </td>
    </tr>
  </tbody>
</table>
</ul>

<br>
<li>Examples:</li>
<ul>
<pre>
RosenbrockFunction f;
arma::mat coordinates = f.GetInitialPoint();

BBS_BB bbsgd(batchSize, 0.01, 0.1, 8000, 1e-4); // Big-Batch SGD with the adaptive stepsize policy.
optimizer.Optimize(f, coordinates);

BBS_Armijo bbsgd(batchSize, 0.01, 0.1, 8000, 1e-4); // Big-Batch SGD with backtracking line search.
optimizer.Optimize(f, coordinates);
</pre>
</ul>
<li>
See also:
<ul>
<li><a href="https://arxiv.org/pdf/1610.05792.pdf">Big Batch SGD: Automated Inference using Adaptive Batch Sizes</a></li>
<li><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">SGD in Wikipedia</a></li>
<li><a href="#part_sgd">SGD</a></li>
</ul>
</li>
<br>
</ul>

<!-- CMAES CONTENT -->
<a name="part_cmaes"></a>
<div class="pagebreak"></div>
<hr class="greyline">
<br>
<br>
<font size=+1><b>CMAES</b></font>
<br>
<br>
CMA-ES - Covariance Matrix Adaptation Evolution Strategy is s a stochastic search algorithm. CMA-ES is a second order approach estimating a positive definite matrix within an iterative procedure using the covariance matrix.
<a name="Attributes"></a>

<br>
<br>
<b>Constructors</b>

<ul>
  <li>CMAES(<i>lambda, lowerBound, upperBound, batchSize, maxIterations, tolerance, selectionPolicy</i>)</li>
  <li>CMAES(<i>lambda, lowerBound, upperBound, batchSize</i>)</li>
  <li>CMAES(<i>lambda, lowerBound, upperBound</i>)</li>
</ul>

<b>Attributes</b>
<ul>
<table style="text-align: left;" border="0" cellpadding="0" cellspacing="0">
<tbody>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>lambda</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>The population size (0 use the default size).</td>
</tr>
<tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>lowerBound</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Lower bound of decision variables.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>upperBound</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Upper bound of decision variables.</td>
</tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>batchSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Batch size to use for the objective calculation.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>tolerance</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum absolute tolerance to terminate algorithm.</td>
</tr>

<tr>
<td><code>SelectionPolicyType</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>selectionPolicy</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Instantiated selection policy used to calculate the objective (default FullSelection).</td>
</tr>

</tr>
</tbody>
</table>
</ul>
<ul>

<li>For convenience the following typedefs have been defined:</li>

<ul>
<table style="text-align: left;" border="0" cellpadding="2" cellspacing="2">
  <tbody>
    <tr>
      <td style="vertical-align: top; text-align: right;">
      <code>ApproxCMAES</code>
      </td>
      <td style="vertical-align: top;">
      &nbsp;=&nbsp;
      </td>
      <td style="vertical-align: top;">
      <code>CMAES&lt;RandomSelection&gt;</code>
      </td>
    </tr>
  </tbody>
</table>
</ul>

<br>
<li>Examples:</li>
<ul>
<pre>
RosenbrockFunction f;
arma::mat coordinates = f.GetInitialPoint();

CMAES&lt;&gt; optimizer(0, -1, 1, 32, 200, 0.1e-4); // CMAES with the FullSelection policy.
optimizer.Optimize(f, coordinates);

ApproxCMAES&lt;&gt;  approxOptimizer(batchSize, 0.01, 0.1, 8000, 1e-4); // CMAES with the RandomSelection policy.
approxOptimizer.Optimize(f, coordinates);
</pre>
</ul>
<li>
See also:
<ul>
<li><a href="http://www.cmap.polytechnique.fr/~nikolaus.hansen/cmaartic.pdf">Completely Derandomized Self-Adaptation in Evolution Strategies</a></li>
<li><a href="https://en.wikipedia.org/wiki/CMA-ES">CMA-ES in Wikipedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Evolution_strategy">Evolution strategy in Wikipedia</a></li>
</ul>
</li>
<br>
</ul>

<!-- CNE CONTENT -->
<a name="part_cne"></a>
<div class="pagebreak"></div>
<hr class="greyline">
<br>
<br>
<font size=+1><b>CNE</b></font>
<br>
<br>
Conventional Neural Evolution is an optimizer that works like biological evolution which selects best candidates based on their fitness scores and creates new generation by mutation and crossover of population.
<a name="Attributes"></a>

<br>
<br>
<b>Constructors</b>

<ul>
  <li>CNE(<i>populationSize, maxGenerations, mutationProb, mutationSize, selectPercent, tolerance, objectiveChange</i>)</li>
  <li>CNE(<i>populationSize, maxGenerations, mutationProb, mutationSize</i>)</li>
  <li>CNE(<i>populationSize, maxGenerations</i>)</li>
</ul>

<b>Attributes</b>
<ul>
<table style="text-align: left;" border="0" cellpadding="0" cellspacing="0">
<tbody>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>populationSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>The number of candidates in the population. This should be at least 4 in size.</td>
</tr>
<tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>maxGenerations</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>The maximum number of generations allowed for CNE.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>mutationProb</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Probability that a weight will get mutated.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>mutationSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>The range of mutation noise to be added. This range is between 0 and mutationSize.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>selectPercent</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>The percentage of candidates to select to become the the next generation.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>tolerance</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>The final value of the objective function for termination. If set to negative value, tolerance is not considered.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>objectiveChange</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Minimum change in best fitness values between two consecutive generations should be greater than threshold. If set to negative value, objectiveChange is not considered.</td>
</tr>

</tr>
</tbody>
</table>
</ul>
<ul>

<br>
<li>Examples:</li>
<ul>
<pre>
RosenbrockFunction f;
arma::mat coordinates = f.GetInitialPoint();

CNE optimizer(200, 10000, 0.2, 0.2, 0.3, 65, 0.1e-4);
optimizer.Optimize(f, coordinates);
</pre>
</ul>
<li>
See also:
<ul>
<li><a href="http://www.cmap.polytechnique.fr/~nikolaus.hansen/cmatutorial110628.pdf">The CMA Evolution Strategy: A Tutorial</a></li>
<li><a href="https://en.wikipedia.org/wiki/Neuroevolution">Neuroevolution in Wikipedia</a></li>
</ul>
</li>
<br>
</ul>

<!-- Frank-Wolfe Algorithm CONTENT -->
<a name="part_frankwolfe"></a>
<div class="pagebreak"></div>
<hr class="greyline">
<br>
<br>
<font size=+1><b>Frank-Wolfe</b></font>
<br>
<br>
Frank-Wolfe is a technique to minimize a continuously differentiable convex function f over a compact convex subset D of a vector space. It is also known as conditional gradient method.
<a name="Attributes"></a>

<br>
<br>
<b>Constructors</b>

<ul>
  <li>FrankWolfe(<i>linearConstrSolver, updateRule, maxIterations, tolerance</i>)</li>
  <li>FrankWolfe(<i>linearConstrSolver, updateRule</i>)</li>
</ul>

<b>Attributes</b>
<ul>
<table style="text-align: left;" border="0" cellpadding="0" cellspacing="0">
<tbody>

<tr>
<td><code>LinearConstrSolverType</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>linearConstrSolver</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Solver for linear constrained problem.</td>
</tr>
<tr>

<tr>
<td><code>UpdateRuleType</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>updateRule</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Rule for updating solution in each iteration.</td>
</tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>maxIterations</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum number of iterations allowed (0 means no limit).</td>
</tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>tolerance</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum absolute tolerance to terminate algorithm.</td>
</tr>

</tr>
</tbody>
</table>
</ul>
<ul>

<li>For convenience the following typedefs have been defined:</li>

<ul>
<table style="text-align: left;" border="0" cellpadding="2" cellspacing="2">
  <tbody>
    <tr>
      <td style="vertical-align: top; text-align: right;">
      <code>OMP</code>
      </td>
      <td style="vertical-align: top;">
      &nbsp;=&nbsp;
      </td>
      <td style="vertical-align: top;">
      <code>FrankWolfe&lt;ConstrLpBallSolver, UpdateSpan>&gt;</code>
      </td>
    </tr>
  </tbody>
</table>
</ul>

<br>
<li>Examples:</li>
<ul>
<pre>
</pre>
</ul>
<li>
See also:
<ul>
<li><a href="https://pdfs.semanticscholar.org/3a24/54478a94f1e66a3fc5d209e69217087acbc0.pdf">An algorithm for quadratic programming</a></li>
<li><a href="https://en.wikipedia.org/wiki/Frank%E2%80%93Wolfe_algorithm">Frank-Wolfe in Wikipedia</a></li>
</ul>
</li>
<br>
</ul>

<!-- Gradient Descent CONTENT -->
<a name="part_gradientdescent"></a>
<div class="pagebreak"></div>
<hr class="greyline">
<br>
<br>
<font size=+1><b>Gradient Descent</b></font>
<br>
<br>
Gradient Descent is a technique to minimize a function. To find a local minimum of a function using gradient descent, one takes steps proportional to the negative of the gradient of the function at the current point.
<a name="Attributes"></a>

<br>
<br>
<b>Constructors</b>

<ul>
  <li>GradientDescent(<i>stepSize, maxIterations, tolerance</i>)</li>
  <li>GradientDescent(<i>stepSize</i>)</li>
</ul>

<b>Attributes</b>
<ul>
<table style="text-align: left;" border="0" cellpadding="0" cellspacing="0">
<tbody>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>StepSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Step size for each iteration.</td>
</tr>
<tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>maxIterations</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum number of iterations allowed (0 means no limit).</td>
</tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>tolerance</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum absolute tolerance to terminate algorithm.</td>
</tr>

</tr>
</tbody>
</table>
</ul>
<ul>

<br>
<li>Examples:</li>
<ul>
<pre>
RosenbrockFunction f;
arma::mat coordinates = f.GetInitialPoint();

GradientDescent optimizer(0.001, 0, 1e-15);
optimizer.Optimize(f, coordinates);
</pre>
</ul>
<li>
See also:
<ul>
<li><a href="https://en.wikipedia.org/wiki/Gradient_descent">Gradient descent in Wikipedia</a></li>
</ul>
</li>
<br>
</ul>


<!-- IQN CONTENT -->
<a name="part_iqn"></a>
<div class="pagebreak"></div>
<hr class="greyline">
<br>
<br>
<font size=+1><b>IQN</b></font>
<br>
<br>
The Incremental Quasi-Newton belongs to the family of stochastic and incremental methods that have a cost per iteration independent of n. IQN iterations are a stochastic version of BFGS iterations that use memory to reduce the variance of stochastic approximations.
<a name="Attributes"></a>

<br>
<br>
<b>Constructors</b>

<ul>
  <li>IQN(<i>stepSize, batchSize, maxIterations, tolerance</i>)</li>
  <li>IQN(<i>stepSize</i>)</li>
</ul>

<b>Attributes</b>
<ul>
<table style="text-align: left;" border="0" cellpadding="0" cellspacing="0">
<tbody>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>StepSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Step size for each iteration.</td>
</tr>
<tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>batchSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Size of each batch.</td>
</tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>maxIterations</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum number of iterations allowed (0 means no limit).</td>
</tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>tolerance</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum absolute tolerance to terminate algorithm.</td>
</tr>

</tr>
</tbody>
</table>
</ul>
<ul>

<br>
<li>Examples:</li>
<ul>
<pre>
RosenbrockFunction f;
arma::mat coordinates = f.GetInitialPoint();

IQN optimizer(0.01, 1, 5000, 1e-5);
optimizer.Optimize(f, coordinates);
</pre>
</ul>
<li>
See also:
<ul>
<li><a href="https://arxiv.org/abs/1702.00709">IQN: An Incremental Quasi-Newton Method with Local Superlinear Convergence Rate</a></li>
<li><a href="https://arxiv.org/abs/1401.7020">A Stochastic Quasi-Newton Method for Large-Scale Optimization</a></li>

</ul>
</li>
<br>
</ul>


<!-- Katyusha CONTENT -->
<a name="part_katyusha"></a>
<div class="pagebreak"></div>
<hr class="greyline">
<br>
<br>
<font size=+1><b>Katyusha</b></font>
<br>
<br>
Katyusha is a direct, primal-only stochastic gradient method which uses a "negative momentum" on top of Nesterov’s momentum.
<a name="Attributes"></a>

<br>
<br>
<b>Constructors</b>

<ul>
  <li>Katyusha(<i>convexity, lipschitz, batchSize, maxIterations, innerIterations, tolerance, shuffle</i>)</li>
  <li>Katyusha(<i>convexity, lipschitz, batchSize</i>)</li>
  <li>Katyusha(<i>convexity, lipschitz</i>)</li>
</ul>

<b>Attributes</b>
<ul>
<table style="text-align: left;" border="0" cellpadding="0" cellspacing="0">
<tbody>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>convexity</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>The population size (0 use the default size).</td>
</tr>
<tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>lipschitz</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>The regularization parameter.</td>
</tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>batchSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>The Lipschitz constant.</td>
</tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>maxIterations</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum number of iterations allowed (0 means no limit).</td>
</tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>innerIterations</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>The number of inner iterations allowed (0 means n / batchSize). Note that the full gradient is only calculated in the outer iteration.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>tolerance</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum absolute tolerance to terminate algorithm.</td>
</tr>

<tr>
<td><code>bool</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>shuffle</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>If true, the function order is shuffled; otherwise, each function is visited in linear order.</td>
</tr>

</tr>
</tbody>
</table>
</ul>
<ul>


<li>For convenience the following typedefs have been defined:</li>

<ul>
<table style="text-align: left;" border="0" cellpadding="2" cellspacing="2">
  <tbody>
    <tr>
      <td style="vertical-align: top; text-align: right;">
      <code>KatyushaProximal</code>
      </td>
      <td style="vertical-align: top;">
      &nbsp;=&nbsp;
      </td>
      <td style="vertical-align: top;">
      <code>KatyushaType&lt;true&gt;</code>
      </td>
    </tr>
  </tbody>
</table>
</ul>

<br>
<li>Examples:</li>
<ul>
<pre>
RosenbrockFunction f;
arma::mat coordinates = f.GetInitialPoint();

Katyusha optimizer(1.0, 10.0, 1, 100, 0, 1e-10, true); // Without proximal update.
optimizer.Optimize(f, coordinates);

KatyushaProximal proximalOptimizer(1.0, 10.0, 1, 100, 0, 1e-10, true);  // With proximal update.
proximalOptimizer.Optimize(f, coordinates);
</pre>
</ul>
<li>
See also:
<ul>
<li><a href="https://arxiv.org/abs/1603.05953">Katyusha: The First Direct Acceleration of Stochastic Gradient Methods</a></li>
<li><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">Stochastic gradient descent in Wikipedia</a></li>
</ul>
</li>
<br>
</ul>


<!-- L_BFGS CONTENT -->
<a name="part_lbfgs"></a>
<div class="pagebreak"></div>
<hr class="greyline">
<br>
<br>
<font size=+1><b>L-BFGS</b></font>
<br>
<br>
L-BFGS is an optimization algorithm in the family of quasi-Newton methods that approximates the Broyden–Fletcher–Goldfarb–Shanno (BFGS) algorithm using a limited amount of computer memory.
<a name="Attributes"></a>

<br>
<br>
<b>Constructors</b>

<ul>
  <li>L_BFGS(<i>numBasis, maxIterations, armijoConstant, wolfe, minGradientNorm, factr, maxLineSearchTrials, minStep, maxStep</i>)</li>
  <li>L_BFGS(<i>numBasis, maxIterations, armijoConstant, wolfe, minGradientNorm, factr, maxLineSearchTrials</i>)</li>
</ul>

<b>Attributes</b>
<ul>
<table style="text-align: left;" border="0" cellpadding="0" cellspacing="0">
<tbody>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>numBasis</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Number of memory points to be stored (default 5).</td>
</tr>
<tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>maxIterations</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum number of iterations for the optimization (0 means no limit and may run indefinitely).</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>armijoConstant</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Controls the accuracy of the line search routine for determining the Armijo condition.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>wolfe</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Parameter for detecting the Wolfe condition.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>minGradientNorm</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Minimum gradient norm required to continue the optimization.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>factr</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Minimum relative function value decrease to continue the optimization.</td>
</tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>maxLineSearchTrials</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>The maximum number of trials for the line search (before giving up).</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>minStep</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>The minimum step of the line search.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>maxStep</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>The maximum step of the line search.</td>
</tr>

</tr>
</tbody>
</table>
</ul>
<ul>

<br>
<li>Examples:</li>
<ul>
<pre>
RosenbrockFunction f;
arma::mat coordinates = f.GetInitialPoint();

L_BFGS optimizer(20);
optimizer.Optimize(f, coordinates);
</pre>
</ul>
<li>
See also:
<ul>
<li><a href="https://onlinelibrary.wiley.com/doi/full/10.1002/nme.1620141104">The solution of non linear finite element equations</a></li>
<li><a href="https://www.jstor.org/stable/2006193">Updating Quasi-Newton Matrices with Limited Storage</a></li>
<li><a href="https://en.wikipedia.org/wiki/Limited-memory_BFGS">Limited-memory BFGS in Wikipedia</a></li>

</ul>
</li>
<br>
</ul>


<!-- RMSProp CONTENT -->
<a name="part_rmsprop"></a>
<div class="pagebreak"></div>
<hr class="greyline">
<br>
<br>
<font size=+1><b>RMSProp</b></font>
<br>
<br>
RMSProp utilizes the magnitude of recent gradients to normalize the gradients.
<a name="Attributes"></a>

<br>
<br>
<b>Constructors</b>

<ul>
  <li>RMSProp(<i>stepSize, batchSize, alpha, epsilon, maxIterations, tolerance, shuffle</i>)</li>
  <li>RMSProp(<i>stepSize, batchSize</i>)</li>
</ul>

<b>Attributes</b>
<ul>
<table style="text-align: left;" border="0" cellpadding="0" cellspacing="0">
<tbody>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>stepSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Step size for each iteration.</td>
</tr>
<tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>batchSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Number of points to process in each step.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>alpha</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Smoothing constant, similar to that used in AdaDelta and momentum methods.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>epsilon</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Value used to initialise the mean squared gradient parameter.</td>
</tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>maxIterations</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum number of iterations allowed (0 means no limit).</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>tolerance</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum absolute tolerance to terminate algorithm.</td>
</tr>

<tr>
<td><code>bool</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>shuffle</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>If true, the function order is shuffled; otherwise, each function is visited in linear order.</td>
</tr>

</tr>
</tbody>
</table>
</ul>
<ul>

<br>
<li>Examples:</li>
<ul>
<pre>
RosenbrockFunction f;
arma::mat coordinates = f.GetInitialPoint();

RMSProp optimizer(1e-3, 1, 0.99, 1e-8, 5000000, 1e-9, true);
optimizer.Optimize(f, coordinates);
</pre>
</ul>
<li>
See also:
<ul>
<li><a href="http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf">Divide the gradient by a running average of its recent magnitude</a></li>
<li><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#RMSProp">Stochastic gradient descent in Wikipedia</a></li>

</ul>
</li>
<br>
</ul>

<!-- Simulated Annealing (SA) CONTENT -->
<a name="part_simulatedannealing"></a>
<div class="pagebreak"></div>
<hr class="greyline">
<br>
<br>
<font size=+1><b>Simulated Annealing (SA)</b></font>
<br>
<br>
Simulated Annealing is an stochastic optimization algorithm which is able to deliver near-optimal results quickly without knowing the gradient of the function being optimized. It has unique hill climbing capability that makes it less vulnerable to local minima.  This implementation uses exponential cooling schedule and feedback move control by default, but the cooling schedule can be changed via a template parameter.
<a name="Attributes"></a>

<br>
<br>
<b>Constructors</b>

<ul>
  <li>SA(<i>coolingSchedule, maxIterations, initT, initMoves, moveCtrlSweep, tolerance, maxToleranceSweep, maxMoveCoef, initMoveCoef, gain</i>)</li>
  <li>SA(<i>coolingSchedule, maxIterations</i>)</li>
</ul>

<b>Attributes</b>
<ul>
<table style="text-align: left;" border="0" cellpadding="0" cellspacing="0">
<tbody>

<tr>
<td><code>CoolingScheduleType</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>coolingSchedule</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Instantiated cooling schedule (default ExponentialSchedule).</td>
</tr>
<tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>maxIterations</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>maxIterations Maximum number of iterations allowed (0 indicates no limit).</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>initT</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Initial temperature.</td>
</tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>initMoves</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Number of initial iterations without changing temperature.</td>
</tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>moveCtrlSweep</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Sweeps per feedback move control.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>tolerance</b></code>
</td><td>&nbsp;&nbsp;&nbsp;</td>
<td>Tolerance to consider system frozen.</td>
</tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>maxToleranceSweep</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum sweeps below tolerance to consider system frozen.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>maxMoveCoef</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum move size.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>initMoveCoef</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Initial move size.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>gain</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Proportional control in feedback move control.</td>
</tr>

</tr>
</tbody>
</table>
</ul>
<ul>

<br>
<li>Examples:</li>
<ul>
<pre>
RosenbrockFunction f;
arma::mat coordinates = f.GetInitialPoint();

SA&lt;ExponentialSchedule&gt; optimizer(ExponentialSchedule(), 1000000, 1000., 1000, 100, 1e-10, 3, 1.5, 0.5, 0.3
optimizer.Optimize(f, coordinates);
</pre>
</ul>
<li>
See also:
<ul>
<li><a href="http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf">Divide the gradient by a running average of its recent magnitude</a></li>
<li><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#RMSProp">Stochastic gradient descent in Wikipedia</a></li>

</ul>
</li>
<br>
</ul>

<!-- SARAH CONTENT -->
<a name="part_sarah"></a>
<div class="pagebreak"></div>
<hr class="greyline">
<br>
<br>
<font size=+1><b>StochAstic Recusive gRadient algoritHm (SARAH/SARAH+)</b></font>
<br>
<br>
StochAstic Recusive gRadient algoritHm (SARAH), is a variance reducing stochastic recursive gradient algorithm which employs the stochastic recursive gradient, for solving empirical loss minimization for the case of nonconvex losses.
<a name="Attributes"></a>

<br>
<br>
<b>Constructors</b>

<ul>
  <li>SARAH(<i>stepSize, batchSize, maxIterations, innerIterations, tolerance, shuffle, updatePolicy</i>)</li>
  <li>SARAH(<i>stepSize, batchSize</i>)</li>
</ul>

<b>Attributes</b>
<ul>
<table style="text-align: left;" border="0" cellpadding="0" cellspacing="0">
<tbody>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>stepSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Instantiated cooling schedule (default ExponentialSchedule).</td>
</tr>
<tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>batchSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Batch size to use for each step.</td>
</tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>maxIterations</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum number of iterations allowed (0 means no limit).</td>
</tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>innerIterations</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>The number of inner iterations allowed (0 means n / batchSize). Note that the full gradient is only calculated in the outer iteration.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>tolerance</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum absolute tolerance to terminate algorithm.</td>
</tr>

<tr>
<td><code>bool</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>shuffle</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>If true, the function order is shuffled; otherwise, each function is visited in linear order.</td>
</tr>

<tr>
<td><code>UpdatePolicyType</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>updatePolicy</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Instantiated update policy used to adjust the given parameters.</td>
</tr>

</tr>
</tbody>
</table>
</ul>
<ul>

<li>For convenience the following typedefs have been defined:</li>

<ul>
<table style="text-align: left;" border="0" cellpadding="2" cellspacing="2">
  <tbody>
    <tr>
      <td style="vertical-align: top; text-align: right;">
      <code>SARAH</code>
      </td>
      <td style="vertical-align: top;">
      &nbsp;=&nbsp;
      </td>
      <td style="vertical-align: top;">
      <code>SARAHType&lt;SARAHUpdate&gt;</code>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top; text-align: right;">
      <code>SARAH_Plus</code>
      </td>
      <td style="vertical-align: top;">
      &nbsp;=&nbsp;
      </td>
      <td style="vertical-align: top;">
      <code>SARAHType&lt;SARAHPlusUpdate&gt;</code>
      </td>
    </tr>
  </tbody>
</table>
</ul>

<br>
<li>Examples:</li>
<ul>
<pre>
RosenbrockFunction f;
arma::mat coordinates = f.GetInitialPoint();

SARAH optimizer(0.01, 1, 5000, 0, 1e-5, true);  // Standard stochastic variance reduced gradient.
optimizer.Optimize(f, coordinates);

SARAH_Plus optimizerPlus(0.01, 1, 5000, 0, 1e-5, true);  // Stochastic variance reduced gradient with Barzilai-Borwein.
optimizerPlus.Optimize(f, coordinates);
</pre>
</ul>
<li>
See also:
<ul>
<li><a href="https://arxiv.org/abs/1705.07261">Stochastic Recursive Gradient Algorithm for Nonconvex Optimization</a></li>
<li><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">Stochastic gradient descent in Wikipedia</a></li>

</ul>
</li>
<br>
</ul>

<!-- SGDR CONTENT -->
<a name="part_sgdr"></a>
<div class="pagebreak"></div>
<hr class="greyline">
<br>
<br>
<font size=+1><b>Stochastic Gradient Descent with Restarts (SGDR)</b></font>
<br>
<br>
SGDR is based on Mini-batch Stochastic Gradient Descent class and simulates a new warm-started run/restart once a number of epochs are performed.
<a name="Attributes"></a>
<br>
<br>
<li>Examples:</li>
<br>
<br>
<b>Constructors</b>

<ul>
  <li>SGDR(<i>epochRestart, multFactor, batchSize, stepSize, maxIterations, tolerance, shuffle, updatePolicy</i>)</li>
  <li>SGDR(<i>epochRestart, multFactor, batchSize, stepSize</i>)</li>
</ul>

<b>Attributes</b>
<ul>
<table style="text-align: left;" border="0" cellpadding="0" cellspacing="0">
<tbody>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>epochRestart</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Initial epoch where decay is applied.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>multFactor</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Batch size multiplication factor.</td>
</tr>
<tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>batchSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Size of each mini-batch.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>stepSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Step size for each iteration.</td>
</tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>maxIterations</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum number of iterations allowed (0 means no limit).</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>tolerance</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum absolute tolerance to terminate algorithm.</td>
</tr>

<tr>
<td><code>bool</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>shuffle</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>If true, the mini-batch order is shuffled; otherwise, each mini-batch is visited in linear order.</td>
</tr>

<tr>
<td><code>UpdatePolicyType</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>updatePolicy</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Instantiated update policy used to adjust the given parameters.</td>
</tr>

</tr>
</tbody>
</table>
</ul>
<ul>

<br>
<li>Examples:</li>
<ul>
<pre>
RosenbrockFunction f;
arma::mat coordinates = f.GetInitialPoint();

SGDR&lt;&gt; optimizer(50, 2.0, 1, 0.01, 10000, 1e-3);
optimizer.Optimize(f, coordinates);
</pre>
</ul>
<li>
See also:
<ul>
<li><a href="https://arxiv.org/abs/1608.03983">SGDR: Stochastic Gradient Descent with Warm Restarts</a></li>
<li><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">Stochastic gradient descent in Wikipedia</a></li>

</ul>
</li>
<br>
</ul>

<!-- SnapshotSGDR CONTENT -->
<a name="part_snapshotsgdr"></a>
<div class="pagebreak"></div>
<hr class="greyline">
<br>
<br>
<font size=+1><b>Snapshot Stochastic Gradient Descent with Restarts (SnapshotSGDR)</b></font>
<br>
<br>
Mini-batch Stochastic Gradient Descent class and simulates a new warm-started run/restart once a number of epochs are performed using the Snapshot ensembles technique.
<a name="Attributes"></a>
<br>
<br>
<li>Examples:</li>
<br>
<br>
<b>Constructors</b>

<ul>
  <li>SnapshotSGDR(<i>epochRestart, multFactor, batchSize, stepSize, maxIterations, tolerance, shuffle, snapshots, accumulate, updatePolicy</i>)</li>
  <li>SnapshotSGDR(<i>epochRestart, multFactor, batchSize, stepSize</i>)</li>
</ul>

<b>Attributes</b>
<ul>
<table style="text-align: left;" border="0" cellpadding="0" cellspacing="0">
<tbody>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>epochRestart</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Initial epoch where decay is applied.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>multFactor</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Batch size multiplication factor.</td>
</tr>
<tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>batchSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Size of each mini-batch.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>stepSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Step size for each iteration.</td>
</tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>maxIterations</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum number of iterations allowed (0 means no limit).</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>tolerance</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum absolute tolerance to terminate algorithm.</td>
</tr>

<tr>
<td><code>bool</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>shuffle</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>If true, the mini-batch order is shuffled; otherwise, each mini-batch is visited in linear order.</td>
</tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>snapshots</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum number of snapshots.</td>
</tr>

<tr>
<td><code>bool</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>accumulate</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Accumulate the snapshot parameter (default true).</td>
</tr>

<tr>
<td><code>UpdatePolicyType</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>updatePolicy</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Instantiated update policy used to adjust the given parameters.</td>
</tr>

</tr>
</tbody>
</table>
</ul>
<ul>

<br>
<li>Examples:</li>
<ul>
<pre>
RosenbrockFunction f;
arma::mat coordinates = f.GetInitialPoint();

SnapshotSGDR&lt;&gt; optimizer(50, 2.0, 1, 0.01, 10000, 1e-3);
optimizer.Optimize(f, coordinates);
</pre>
</ul>
<li>
See also:
<ul>
<li><a href="https://arxiv.org/abs/1704.00109">Snapshot ensembles: Train 1, get m for free</a></li>
<li><a href="https://arxiv.org/abs/1608.03983">SGDR: Stochastic Gradient Descent with Warm Restarts</a></li>
<li><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">Stochastic gradient descent in Wikipedia</a></li>

</ul>
</li>
<br>
</ul>

<!-- SMORMS3 CONTENT -->
<a name="part_smorms3"></a>
<div class="pagebreak"></div>
<hr class="greyline">
<br>
<br>
<font size=+1><b>SMORMS3</b></font>
<br>
<br>
SMORMS3 is a hybrid of RMSprop, which is trying to estimate a safe and optimal distance based on curvature or perhaps just normalizing the stepsize in the parameter space.
<a name="Attributes"></a>
<br>
<br>
<li>Examples:</li>
<br>
<br>
<b>Constructors</b>

<ul>
  <li>SMORMS3(<i>stepSize, batchSize, epsilon, maxIterations, tolerance</i>)</li>
  <li>SMORMS3(<i>stepSize, batchSize</i>)</li>
</ul>

<b>Attributes</b>
<ul>
<table style="text-align: left;" border="0" cellpadding="0" cellspacing="0">
<tbody>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>stepSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Step size for each iteration.</td>
</tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>batchSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Number of points to process at each step.</td>
</tr>
<tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>epsilon</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Value used to initialise the mean squared gradient parameter.</td>
</tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>maxIterations</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum number of iterations allowed (0 means no limit).</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>tolerance</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum absolute tolerance to terminate algorithm.</td>
</tr>

<tr>
<td><code>bool</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>shuffle</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>If true, the mini-batch order is shuffled; otherwise, each mini-batch is visited in linear order.</td>
</tr>

</tr>
</tbody>
</table>
</ul>
<ul>

<br>
<li>Examples:</li>
<ul>
<pre>
RosenbrockFunction f;
arma::mat coordinates = f.GetInitialPoint();

SMORMS3 optimizer(0.001, 1, 1e-16, 5000000, 1e-9, true);
optimizer.Optimize(f, coordinates);
</pre>
</ul>
<li>
See also:
<ul>
<li><a href="https://sifter.org/simon/journal/20150420.html">RMSprop loses to SMORMS3 - Beware the Epsilon!</a></li>
<li><a href="#part_rmsprop">RMSProp</a></li>
<li><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">Stochastic gradient descent in Wikipedia</a></li>

</ul>
</li>
<br>
</ul>

<!-- SVRG CONTENT -->
<a name="part_svrg"></a>
<div class="pagebreak"></div>
<hr class="greyline">
<br>
<br>
<font size=+1><b>Standard stochastic variance reduced gradient (SVRG)</b></font>
<br>
<br>
Stochastic Variance Reduced Gradient is a technique for minimizing smooth and strongly convex problems.
<a name="Attributes"></a>

<br>
<br>
<b>Constructors</b>

<ul>
  <li>SVRG(<i>stepSize, batchSize, maxIterations, innerIterations, tolerance, shuffle, updatePolicy, decayPolicy, resetPolicy</i>)</li>
  <li>SVRG(<i>stepSize, batchSize, maxIterations, innerIterations</i>)</li>
  <li>SVRG(<i>stepSize</i>)</li>
</ul>

<b>Attributes</b>
<ul>
<table style="text-align: left;" border="0" cellpadding="0" cellspacing="0">
<tbody>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>stepSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Step size for each iteration.</td>
</tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>batchSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Initial batch size.</td>
</tr>
<tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>maxIterations</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum number of iterations allowed (0 means no limit).</td>
</tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>innerIterations</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>The number of inner iterations allowed (0 means n / batchSize). Note that the full gradient is only calculated in the outer iteration.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>tolerance</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum absolute tolerance to terminate algorithm.</td>
</tr>

<tr>
<td><code>bool</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>shuffle</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>If true, the batch order is shuffled; otherwise, each batch is visited in linear order.</td>
</tr>

<tr>
<td><code>UpdatePolicyType</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>updatePolicy</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Instantiated update policy used to adjust the given parameters.</td>
</tr>

<tr>
<td><code>DecayPolicyType</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>decayPolicy</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Instantiated decay policy used to adjust the step size.</td>
</tr>

<tr>
<td><code>bool</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>resetPolicy</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Flag that determines whether update policy parameters are reset before every Optimize call.</td>
</tr>

</tr>
</tbody>
</table>
</ul>
<ul>

<li>For convenience the following typedefs have been defined:</li>

<ul>
<table style="text-align: left;" border="0" cellpadding="2" cellspacing="2">
  <tbody>
    <tr>
      <td style="vertical-align: top; text-align: right;">
      <code>SVRG</code>
      </td>
      <td style="vertical-align: top;">
      &nbsp;=&nbsp;
      </td>
      <td style="vertical-align: top;">
      <code>SVRGType&lt;SVRGUpdate, NoDecay&gt;</code>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top; text-align: right;">
      <code>SVRG_BB</code>
      </td>
      <td style="vertical-align: top;">
      &nbsp;=&nbsp;
      </td>
      <td style="vertical-align: top;">
      <code>SVRGType&lt;SVRGUpdate, BarzilaiBorweinDecay&gt;</code>
      </td>
    </tr>
  </tbody>
</table>
</ul>

<br>
<li>Examples:</li>
<ul>
<pre>
RosenbrockFunction f;
arma::mat coordinates = f.GetInitialPoint();

SVRG optimizer(0.005, 1, 300, 0, 1e-10, true); // Standard stochastic variance reduced gradient.
optimizer.Optimize(f, coordinates);

SVRG_BB bbOptimizer(0.005, batchSize, 300, 0, 1e-10, true, SVRGUpdate(), BarzilaiBorweinDecay(0.1)); // Stochastic variance reduced gradient with Barzilai-Borwein.
bbOptimizer.Optimize(f, coordinates);
</pre>
</ul>
<li>
See also:
<ul>
<li><a href="https://papers.nips.cc/paper/4937-accelerating-stochastic-gradient-descent-using-predictive-variance-reduction.pdf">Accelerating Stochastic Gradient Descent using Predictive Variance Reduction</a></li>
<li><a href="#part_sgd">SGD</a></li>
<li><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">SGD in Wikipedia</a></li>
</ul>
</li>
<br>
</ul>

<!-- SMORMS3 CONTENT -->
<a name="part_smorms3"></a>
<div class="pagebreak"></div>
<hr class="greyline">
<br>
<br>
<font size=+1><b>SMORMS3</b></font>
<br>
<br>
SMORMS3 is a hybrid of RMSprop, which is trying to estimate a safe and optimal distance based on curvature or perhaps just normalizing the stepsize in the parameter space.
<a name="Attributes"></a>
<br>
<br>
<li>Examples:</li>
<br>
<br>
<b>Constructors</b>

<ul>
  <li>SMORMS3(<i>stepSize, batchSize, epsilon, maxIterations, tolerance</i>)</li>
  <li>SMORMS3(<i>stepSize, batchSize</i>)</li>
</ul>

<b>Attributes</b>
<ul>
<table style="text-align: left;" border="0" cellpadding="0" cellspacing="0">
<tbody>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>stepSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Step size for each iteration.</td>
</tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>batchSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Number of points to process at each step.</td>
</tr>
<tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>epsilon</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Value used to initialise the mean squared gradient parameter.</td>
</tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>maxIterations</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum number of iterations allowed (0 means no limit).</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>tolerance</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum absolute tolerance to terminate algorithm.</td>
</tr>

<tr>
<td><code>bool</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>shuffle</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>If true, the mini-batch order is shuffled; otherwise, each mini-batch is visited in linear order.</td>
</tr>

</tr>
</tbody>
</table>
</ul>
<ul>

<br>
<li>Examples:</li>
<ul>
<pre>
RosenbrockFunction f;
arma::mat coordinates = f.GetInitialPoint();

SMORMS3 optimizer(0.001, 1, 1e-16, 5000000, 1e-9, true);
optimizer.Optimize(f, coordinates);
</pre>
</ul>
<li>
See also:
<ul>
<li><a href="https://sifter.org/simon/journal/20150420.html">RMSprop loses to SMORMS3 - Beware the Epsilon!</a></li>
<li><a href="#part_rmsprop">RMSProp</a></li>
<li><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">Stochastic gradient descent in Wikipedia</a></li>

</ul>
</li>
<br>
</ul>

<!-- SPALeRASGD CONTENT -->
<a name="part_spalerasgd"></a>
<div class="pagebreak"></div>
<hr class="greyline">
<br>
<br>
<font size=+1><b>SPALeRA Stochastic Gradient Descent (SPALeRASGD).</b></font>
<br>
<br>
SALERA involves two components: a learning rate adaptation scheme, which ensures that the learning system goes as fast as it can; and a catastrophic event manager, which is in charge of detecting undesirable behaviors and getting the system back on track.
<a name="Attributes"></a>

<br>
<br>
<b>Constructors</b>

<ul>
  <li>SPALeRA(<i>stepSize, batchSize, maxIterations, tolerance, lambda, alpha, epsilon, adaptRate, shuffle, decayPolicy, resetPolicy</i>)</li>
  <li>SPALeRA(<i>stepSize, batchSize, maxIterations, tolerance</i>)</li>
  <li>SPALeRA(<i>stepSize, batchSize</i>)</li>
</ul>

<b>Attributes</b>
<ul>
<table style="text-align: left;" border="0" cellpadding="0" cellspacing="0">
<tbody>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>stepSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Step size for each iteration.</td>
</tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>batchSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Initial batch size.</td>
</tr>
<tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>maxIterations</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum number of iterations allowed (0 means no limit).</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>tolerance</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum absolute tolerance to terminate algorithm.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>lambda</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Page-Hinkley update parameter.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>alpha</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Memory parameter of the Agnostic Learning Rate adaptation.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>epsilon</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Numerical stability parameter.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>adaptRate</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Agnostic learning rate update rate. shuffle If true, the function order is shuffled; otherwise, each function is visited in linear order.</td>
</tr>
<tr>
<td><code>bool</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>shuffle</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>If true, the batch order is shuffled; otherwise, each batch is visited in linear order.</td>
</tr>

<tr>
<td><code>DecayPolicyType</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>decayPolicy</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Instantiated decay policy used to adjust the step size.</td>
</tr>

<tr>
<td><code>bool</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>resetPolicy</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Flag that determines whether update policy parameters are reset before every Optimize call.</td>
</tr>

</tr>
</tbody>
</table>
</ul>
<ul>

<br>
<li>Examples:</li>
<ul>
<pre>
RosenbrockFunction f;
arma::mat coordinates = f.GetInitialPoint();

SPALeRASGD&lt;&gt; optimizer(0.05, 1, 10000, 1e-4);
optimizer.Optimize(f, coordinates);
</pre>
</ul>
<li>
See also:
<ul>
<li><a href="https://arxiv.org/abs/1709.01427">Stochastic Gradient Descent: Going As Fast As Possible But Not Faster</a></li>
<li><a href="#part_sgd">SGD</a></li>
<li><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">SGD in Wikipedia</a></li>
</ul>
</li>
<br>
</ul>

<!-- SGD CONTENT -->
<a name="part_sgd"></a>
<div class="pagebreak"></div>
<hr class="greyline">
<br>
<br>
<font size=+1><b>Stochastic Gradient Descent (SGD)</b></font>
<br>
<br>
Stochastic Gradient Descent is a technique for minimizing a function which can be expressed as a sum of other functions.
<a name="Attributes"></a>

<br>
<br>
<b>Constructors</b>

<ul>
  <li>SGD(<i>stepSize, batchSize, maxIterations, tolerance, shuffle, updatePolicy, decayPolicy, resetPolicy</i>)</li>
  <li>SGD(<i>stepSize, batchSize, maxIterations, tolerance, shuffle</i>)</li>
  <li>SGD(<i>stepSize</i>)</li>
</ul>

<b>Attributes</b>
<ul>
<table style="text-align: left;" border="0" cellpadding="0" cellspacing="0">
<tbody>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>stepSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Step size for each iteration.</td>
</tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>batchSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Initial batch size.</td>
</tr>
<tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>maxIterations</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum number of iterations allowed (0 means no limit).</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>tolerance</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum absolute tolerance to terminate algorithm.</td>
</tr>

<tr>
<td><code>bool</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>shuffle</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>If true, the batch order is shuffled; otherwise, each batch is visited in linear order.</td>
</tr>

<tr>
<td><code>UpdatePolicyType</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>updatePolicy</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Instantiated update policy used to adjust the given parameters.</td>
</tr>

<tr>
<td><code>DecayPolicyType</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>decayPolicy</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Instantiated decay policy used to adjust the step size.</td>
</tr>

<tr>
<td><code>bool</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>resetPolicy</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Flag that determines whether update policy parameters are reset before every Optimize call.</td>
</tr>

</tr>
</tbody>
</table>
</ul>
<ul>


<li>For convenience the following typedefs have been defined:</li>

<ul>
<table style="text-align: left;" border="0" cellpadding="2" cellspacing="2">
  <tbody>
    <tr>
      <td style="vertical-align: top; text-align: right;">
      <code>StandardSGD</code>
      </td>
      <td style="vertical-align: top;">
      &nbsp;=&nbsp;
      </td>
      <td style="vertical-align: top;">
      <code>SGD&lt;VanillaUpdate&gt;</code>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top; text-align: right;">
      <code>MomentumSGD</code>
      </td>
      <td style="vertical-align: top;">
      &nbsp;=&nbsp;
      </td>
      <td style="vertical-align: top;">
      <code>SGD&lt;MomentumUpdate&gt;</code>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top; text-align: right;">
      <code>NesterovMomentumSGD</code>
      </td>
      <td style="vertical-align: top;">
      &nbsp;=&nbsp;
      </td>
      <td style="vertical-align: top;">
      <code>SGD&lt;NesterovMomentumUpdate&gt;</code>
      </td>
    </tr>
  </tbody>
</table>
</ul>

<br>
<li>Examples:</li>
<ul>
<pre>
RosenbrockFunction f;
arma::mat coordinates = f.GetInitialPoint();

StandardSGD optimizer(0.001, 1, 0, 1e-15, true);  // Standard SGD (vanilla update).
optimizer.Optimize(f, coordinates);

MomentumSGD momentumoOtimizer(0.0003, 1, 2500000, 1e-9, true, MomentumUpdate(0.7));  // Momentum SGD (momentum update).
MomentumUpdate.Optimize(f, coordinates);

MomentumSGD momentumoOtimizer(0.0003, 1, 2500000, 1e-9, true, MomentumUpdate(0.7));  // Momentum SGD (momentum update).
momentumoOtimizer.Optimize(f, coordinates);

NesterovMomentumSGD nesterovOptimizer(0.0001, 1, 0, 1e-15, true, NesterovMomentumUpdate(0.9));  // Nesterov Momentum SGD (nesterov update).
nesterovOptimizer.Optimize(f, coordinates);
</pre>
</ul>
<li>
See also:
<ul>
<li><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">SGD in Wikipedia</a></li>
</ul>
</li>
<br>
</ul>

<!-- SCD CONTENT -->
<a name="part_scd"></a>
<div class="pagebreak"></div>
<hr class="greyline">
<br>
<br>
<font size=+1><b>Stochastic Coordinate descent (SCD).</b></font>
<br>
<br>
Stochastic Coordinate descent is a technique for minimizing a function by doing a line search along a single direction at the current point in the iteration. The direction (or "coordinate") can be chosen cyclically, randomly or in a greedy fashion(depending on the DescentPolicy).
<a name="Attributes"></a>

<br>
<br>
<b>Constructors</b>

<ul>
  <li>SCD(<i>stepSize, maxIterations, tolerance, updateInterval, descentPolicy</i>)</li>
  <li>SCD(<i>stepSize, maxIterations, tolerance, updateInterval</i>)</li>
  <li>SCD(<i>stepSize</i>)</li>
</ul>

<b>Attributes</b>
<ul>
<table style="text-align: left;" border="0" cellpadding="0" cellspacing="0">
<tbody>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>stepSize</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Step size for each iteration.</td>
</tr>

<tr>
<td><code>size_t</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>maxIterations</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum number of iterations allowed (0 means no limit).</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>tolerance</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Maximum absolute tolerance to terminate algorithm.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>updateInterval</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
The interval at which the objective is to be reported and checked for convergence.</td>
</tr>

<tr>
<td><code>DescentPolicyType</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>descentPolicy</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>Memory parameter of the Agnostic Learning Rate adaptation.</td>
</tr>

<tr>
<td><code>double</code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td><code><b>epsilon</b></code></td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>he policy to use for picking up the coordinate to descend on.</td>
</tr>

</tr>
</tbody>
</table>
</ul>
<ul>

<br>
<li>Examples:</li>
<ul>
<pre>
RosenbrockFunction f;
arma::mat coordinates = f.GetInitialPoint();

SCD&lt;&gt; optimizer(0.4);
optimizer.Optimize(f, coordinates);
</pre>
</ul>
<li>
See also:
<ul>
<li><a href="https://dl.acm.org/citation.cfm?doid=1553374.1553493">Stochastic methods for l1 regularized loss minimization</a></li>
<li><a href="#part_sgd">SGD</a></li>
<li><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">SGD in Wikipedia</a></li>
</ul>
</li>
<br>
</ul>

<div class="pagebreak"></div><div class="noprint"><hr class="greyline"><br></div>
<a name="api_additions"></a>
<b>History of API Additions, Changes and Deprecations</b>
<br>
<ul>

<li>
API policy: ensmallen follows <a href="https://semver.org/">semantic versioning</a>
</li>
<br>

<!--
<a name="version_120"></a>
<li>Version 1.20:
<ul>
<li>TODO</li>
</ul>
</li>
<br>
-->

<a name="version_110"></a>
<li>Version 1.10:
<ul>
<li>initial release</li>
</ul>
</li>


</ul>

<!-- END CONTENT -->

<br>
<br>
<br>

</div>

</body>
</html>
